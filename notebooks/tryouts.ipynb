{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcf7ad65",
   "metadata": {},
   "source": [
    "# Setup: Build Schema Index\n",
    "\n",
    "First, we need to index the table schemas from our databases so the agent can discover them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "596a0e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "✓ Disconnected from Snowflake\n",
      "Auto-discovered 3 schemas: DATA_MART_MANUFACTURING, DATA_MART_MARKETING, PUBLIC\n",
      "\n",
      "======================================================================\n",
      "[1/3] INDEXING SCHEMA: DATA_MART_MANUFACTURING\n",
      "======================================================================\n",
      "✓ Disconnected from Snowflake\n",
      "Auto-discovered 3 schemas: DATA_MART_MANUFACTURING, DATA_MART_MARKETING, PUBLIC\n",
      "\n",
      "======================================================================\n",
      "[1/3] INDEXING SCHEMA: DATA_MART_MANUFACTURING\n",
      "======================================================================\n",
      "✓ Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Discovering tables in PROD_SALES.DATA_MART_MANUFACTURING...\n",
      "✓ Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Discovering tables in PROD_SALES.DATA_MART_MANUFACTURING...\n",
      "✓ Found 1 tables/views\n",
      "✓ Disconnected from Snowflake\n",
      "\n",
      "Generating metadata documents for 1 tables...\n",
      "  [1/1] Processing PRODUCTS...\n",
      "✓ Found 1 tables/views\n",
      "✓ Disconnected from Snowflake\n",
      "\n",
      "Generating metadata documents for 1 tables...\n",
      "  [1/1] Processing PRODUCTS...\n",
      "✓ Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Discovering tables in PROD_SALES.DATA_MART_MANUFACTURING...\n",
      "✓ Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Discovering tables in PROD_SALES.DATA_MART_MANUFACTURING...\n",
      "✓ Found 1 tables/views\n",
      "✓ Disconnected from Snowflake\n",
      "✓ Found 1 tables/views\n",
      "✓ Disconnected from Snowflake\n",
      "✓ Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "✓ Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "✓ Disconnected from Snowflake\n",
      "✓ Disconnected from Snowflake\n",
      "✓ Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "✓ Connected to Snowflake: PROD_SALES.PUBLIC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Disconnected from Snowflake\n",
      "✓ Generated 1 metadata documents\n",
      "✓ Deleted existing collection: database_schemas\n",
      "\n",
      "Indexing 1 table metadata documents...\n",
      "✓ Indexed 1 tables from schema DATA_MART_MANUFACTURING\n",
      "\n",
      "======================================================================\n",
      "[2/3] INDEXING SCHEMA: DATA_MART_MARKETING\n",
      "======================================================================\n",
      "✓ Indexed 1 tables from schema DATA_MART_MANUFACTURING\n",
      "\n",
      "======================================================================\n",
      "[2/3] INDEXING SCHEMA: DATA_MART_MARKETING\n",
      "======================================================================\n",
      "✓ Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Discovering tables in PROD_SALES.DATA_MART_MARKETING...\n",
      "✓ Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Discovering tables in PROD_SALES.DATA_MART_MARKETING...\n",
      "✓ Found 1 tables/views\n",
      "✓ Disconnected from Snowflake\n",
      "\n",
      "Generating metadata documents for 1 tables...\n",
      "  [1/1] Processing CUSTOMERS...\n",
      "✓ Found 1 tables/views\n",
      "✓ Disconnected from Snowflake\n",
      "\n",
      "Generating metadata documents for 1 tables...\n",
      "  [1/1] Processing CUSTOMERS...\n",
      "✓ Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Discovering tables in PROD_SALES.DATA_MART_MARKETING...\n",
      "✓ Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Discovering tables in PROD_SALES.DATA_MART_MARKETING...\n",
      "✓ Found 1 tables/views\n",
      "✓ Disconnected from Snowflake\n",
      "✓ Found 1 tables/views\n",
      "✓ Disconnected from Snowflake\n",
      "✓ Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "✓ Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "✓ Disconnected from Snowflake\n",
      "✓ Disconnected from Snowflake\n",
      "✓ Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "✓ Connected to Snowflake: PROD_SALES.PUBLIC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Disconnected from Snowflake\n",
      "✓ Generated 1 metadata documents\n",
      "\n",
      "Indexing 1 table metadata documents...\n",
      "✓ Indexed 1 tables from schema DATA_MART_MARKETING\n",
      "\n",
      "======================================================================\n",
      "[3/3] INDEXING SCHEMA: PUBLIC\n",
      "======================================================================\n",
      "✓ Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Discovering tables in PROD_SALES.PUBLIC...\n",
      "✓ Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Discovering tables in PROD_SALES.PUBLIC...\n",
      "✓ Found 0 tables/views\n",
      "✓ Found 0 tables/views\n",
      "✓ Disconnected from Snowflake\n",
      "\n",
      "Generating metadata documents for 0 tables...\n",
      "✓ Generated 0 metadata documents\n",
      "No tables found in schema PUBLIC\n",
      "\n",
      "======================================================================\n",
      "✓ SCHEMA INDEX BUILT SUCCESSFULLY\n",
      "  - Collection: database_schemas\n",
      "  - Schemas indexed: 3\n",
      "  - Total tables indexed: 2\n",
      "  - Path: ./chroma_db\n",
      "======================================================================\n",
      "\n",
      "✓ Disconnected from Snowflake\n",
      "\n",
      "Generating metadata documents for 0 tables...\n",
      "✓ Generated 0 metadata documents\n",
      "No tables found in schema PUBLIC\n",
      "\n",
      "======================================================================\n",
      "✓ SCHEMA INDEX BUILT SUCCESSFULLY\n",
      "  - Collection: database_schemas\n",
      "  - Schemas indexed: 3\n",
      "  - Total tables indexed: 2\n",
      "  - Path: ./chroma_db\n",
      "======================================================================\n",
      "\n",
      "✓ Connected to PostgreSQL: postgres\n",
      "✓ Disconnected from PostgreSQL\n",
      "Auto-discovered 1 schemas: public\n",
      "\n",
      "======================================================================\n",
      "[1/1] INDEXING SCHEMA: public\n",
      "======================================================================\n",
      "✓ Connected to PostgreSQL: postgres\n",
      "Discovering tables in postgres.public...\n",
      "✓ Found 4 tables/views\n",
      "✓ Disconnected from PostgreSQL\n",
      "\n",
      "Generating metadata documents for 4 tables...\n",
      "  [1/4] Processing customers...\n",
      "✓ Connected to PostgreSQL: postgres\n",
      "✓ Disconnected from PostgreSQL\n",
      "Auto-discovered 1 schemas: public\n",
      "\n",
      "======================================================================\n",
      "[1/1] INDEXING SCHEMA: public\n",
      "======================================================================\n",
      "✓ Connected to PostgreSQL: postgres\n",
      "Discovering tables in postgres.public...\n",
      "✓ Found 4 tables/views\n",
      "✓ Disconnected from PostgreSQL\n",
      "\n",
      "Generating metadata documents for 4 tables...\n",
      "  [1/4] Processing customers...\n",
      "✓ Connected to PostgreSQL: postgres\n",
      "Discovering tables in postgres.public...\n",
      "✓ Found 4 tables/views\n",
      "✓ Disconnected from PostgreSQL\n",
      "✓ Connected to PostgreSQL: postgres\n",
      "✓ Disconnected from PostgreSQL\n",
      "✓ Connected to PostgreSQL: postgres\n",
      "Discovering tables in postgres.public...\n",
      "✓ Found 4 tables/views\n",
      "✓ Disconnected from PostgreSQL\n",
      "✓ Connected to PostgreSQL: postgres\n",
      "✓ Disconnected from PostgreSQL\n",
      "✓ Connected to PostgreSQL: postgres\n",
      "✓ Disconnected from PostgreSQL\n",
      "  [2/4] Processing davar...\n",
      "✓ Connected to PostgreSQL: postgres\n",
      "Discovering tables in postgres.public...\n",
      "✓ Found 4 tables/views\n",
      "✓ Disconnected from PostgreSQL\n",
      "✓ Connected to PostgreSQL: postgres\n",
      "✓ Disconnected from PostgreSQL\n",
      "  [2/4] Processing davar...\n",
      "✓ Connected to PostgreSQL: postgres\n",
      "Discovering tables in postgres.public...\n",
      "✓ Found 4 tables/views\n",
      "✓ Disconnected from PostgreSQL\n",
      "✓ Connected to PostgreSQL: postgres\n",
      "✓ Disconnected from PostgreSQL\n",
      "✓ Connected to PostgreSQL: postgres\n",
      "✓ Disconnected from PostgreSQL\n",
      "  [3/4] Processing genesis...\n",
      "✓ Connected to PostgreSQL: postgres\n",
      "Discovering tables in postgres.public...\n",
      "✓ Connected to PostgreSQL: postgres\n",
      "✓ Disconnected from PostgreSQL\n",
      "✓ Connected to PostgreSQL: postgres\n",
      "✓ Disconnected from PostgreSQL\n",
      "  [3/4] Processing genesis...\n",
      "✓ Connected to PostgreSQL: postgres\n",
      "Discovering tables in postgres.public...\n",
      "✓ Found 4 tables/views\n",
      "✓ Disconnected from PostgreSQL\n",
      "✓ Connected to PostgreSQL: postgres\n",
      "✓ Disconnected from PostgreSQL\n",
      "✓ Found 4 tables/views\n",
      "✓ Disconnected from PostgreSQL\n",
      "✓ Connected to PostgreSQL: postgres\n",
      "✓ Disconnected from PostgreSQL\n",
      "✓ Connected to PostgreSQL: postgres\n",
      "✓ Disconnected from PostgreSQL\n",
      "  [4/4] Processing pages...\n",
      "✓ Connected to PostgreSQL: postgres\n",
      "Discovering tables in postgres.public...\n",
      "✓ Found 4 tables/views\n",
      "✓ Disconnected from PostgreSQL\n",
      "✓ Connected to PostgreSQL: postgres\n",
      "✓ Disconnected from PostgreSQL\n",
      "  [4/4] Processing pages...\n",
      "✓ Connected to PostgreSQL: postgres\n",
      "Discovering tables in postgres.public...\n",
      "✓ Found 4 tables/views\n",
      "✓ Disconnected from PostgreSQL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Connected to PostgreSQL: postgres\n",
      "✓ Disconnected from PostgreSQL\n",
      "✓ Connected to PostgreSQL: postgres\n",
      "✓ Disconnected from PostgreSQL\n",
      "✓ Generated 4 metadata documents\n",
      "\n",
      "Indexing 4 table metadata documents...\n",
      "✓ Indexed 4 tables from schema public\n",
      "\n",
      "======================================================================\n",
      "✓ SCHEMA INDEX BUILT SUCCESSFULLY\n",
      "  - Collection: database_schemas\n",
      "  - Schemas indexed: 1\n",
      "  - Total tables indexed: 4\n",
      "  - Path: ./chroma_db\n",
      "======================================================================\n",
      "\n",
      "✓ Indexed 4 tables from schema public\n",
      "\n",
      "======================================================================\n",
      "✓ SCHEMA INDEX BUILT SUCCESSFULLY\n",
      "  - Collection: database_schemas\n",
      "  - Schemas indexed: 1\n",
      "  - Total tables indexed: 4\n",
      "  - Path: ./chroma_db\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.retrieval.schema_indexer import SchemaIndexer\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Index Snowflake first (recreate the collection)\n",
    "snowflake_indexer = SchemaIndexer(connector_type='snowflake')\n",
    "snowflake_indexer.build_schema_index(recreate=True)\n",
    "\n",
    "# Index PostgreSQL second (append to collection)\n",
    "postgres_indexer = SchemaIndexer(connector_type='postgres')\n",
    "postgres_indexer.build_schema_index(recreate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6ba125a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SMART DATA QUALITY CHECK\n",
      "======================================================================\n",
      "User Query: Check for duplicates in Snowflake PRODUCTS table\n",
      "\n",
      "Step 1: Discovering relevant tables...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 3 relevant table(s):\n",
      "\n",
      "  1. [SNOWFLAKE] PROD_SALES.DATA_MART_MANUFACTURING.PRODUCTS\n",
      "     Relevance: 2.93%\n",
      "\n",
      "  2. [SNOWFLAKE] PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "     Relevance: -16.30%\n",
      "\n",
      "  3. [POSTGRES] postgres.public.davar\n",
      "     Relevance: -61.40%\n",
      "\n",
      "Step 2: Building context for agent...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Step 3: Running agent with discovered tables...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `check_dataset_duplicates` with `{'dataset_id': 'PROD_SALES.DATA_MART_MANUFACTURING.PRODUCTS', 'connector_type': 'snowflake'}`\n",
      "\n",
      "\n",
      "\u001b[0m--- Loading data for: PROD_SALES.DATA_MART_MANUFACTURING.PRODUCTS using SNOWFLAKE connector ---\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `check_dataset_duplicates` with `{'dataset_id': 'PROD_SALES.DATA_MART_MANUFACTURING.PRODUCTS', 'connector_type': 'snowflake'}`\n",
      "\n",
      "\n",
      "\u001b[0m--- Loading data for: PROD_SALES.DATA_MART_MANUFACTURING.PRODUCTS using SNOWFLAKE connector ---\n",
      "✓ Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_MANUFACTURING.PRODUCTS\n",
      "✓ Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_MANUFACTURING.PRODUCTS\n",
      "✓ Loaded 30000 rows from Snowflake\n",
      "✓ Loaded 30000 rows from Snowflake\n",
      "✓ Disconnected from Snowflake\n",
      "✓ Disconnected from Snowflake\n",
      "\u001b[36;1m\u001b[1;3m{'dataset_id': 'PROD_SALES.DATA_MART_MANUFACTURING.PRODUCTS', 'duplicate_qty': 626, 'status': 'failure'}\u001b[0m\u001b[36;1m\u001b[1;3m{'dataset_id': 'PROD_SALES.DATA_MART_MANUFACTURING.PRODUCTS', 'duplicate_qty': 626, 'status': 'failure'}\u001b[0m\u001b[32;1m\u001b[1;3mThe duplicate check for the Snowflake table `PROD_SALES.DATA_MART_MANUFACTURING.PRODUCTS` has been completed. There are **626 duplicate rows** detected in the dataset. Let me know if you need further assistance or actions to address this issue.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "======================================================================\n",
      "RESULT\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "SMART DATA QUALITY CHECK\n",
      "======================================================================\n",
      "User Query: Check for duplicates in postgres CUSTOMERS table\n",
      "\n",
      "Step 1: Discovering relevant tables...\n",
      "----------------------------------------------------------------------\n",
      "\u001b[32;1m\u001b[1;3mThe duplicate check for the Snowflake table `PROD_SALES.DATA_MART_MANUFACTURING.PRODUCTS` has been completed. There are **626 duplicate rows** detected in the dataset. Let me know if you need further assistance or actions to address this issue.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "======================================================================\n",
      "RESULT\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "SMART DATA QUALITY CHECK\n",
      "======================================================================\n",
      "User Query: Check for duplicates in postgres CUSTOMERS table\n",
      "\n",
      "Step 1: Discovering relevant tables...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 3 relevant table(s):\n",
      "\n",
      "  1. [POSTGRES] postgres.public.customers\n",
      "     Relevance: 2.76%\n",
      "\n",
      "  2. [SNOWFLAKE] PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "     Relevance: -13.76%\n",
      "\n",
      "  3. [POSTGRES] postgres.public.davar\n",
      "     Relevance: -46.20%\n",
      "\n",
      "Step 2: Building context for agent...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Step 3: Running agent with discovered tables...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `check_dataset_duplicates` with `{'dataset_id': 'postgres.public.customers', 'connector_type': 'postgres'}`\n",
      "\n",
      "\n",
      "\u001b[0m--- Loading data for: postgres.public.customers using POSTGRES connector ---\n",
      "✓ Connected to PostgreSQL: postgres\n",
      "Executing query: SELECT * FROM postgres.public.customers\n",
      "✓ Loaded 16 rows from PostgreSQL\n",
      "✓ Disconnected from PostgreSQL\n",
      "\u001b[36;1m\u001b[1;3m{'dataset_id': 'postgres.public.customers', 'duplicate_qty': 10, 'status': 'failure'}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `check_dataset_duplicates` with `{'dataset_id': 'postgres.public.customers', 'connector_type': 'postgres'}`\n",
      "\n",
      "\n",
      "\u001b[0m--- Loading data for: postgres.public.customers using POSTGRES connector ---\n",
      "✓ Connected to PostgreSQL: postgres\n",
      "Executing query: SELECT * FROM postgres.public.customers\n",
      "✓ Loaded 16 rows from PostgreSQL\n",
      "✓ Disconnected from PostgreSQL\n",
      "\u001b[36;1m\u001b[1;3m{'dataset_id': 'postgres.public.customers', 'duplicate_qty': 10, 'status': 'failure'}\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CihanGirayOner\\Desktop\\git_repos\\llm_dq_agent\\src\\connectors\\postgres_connector.py:78: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(sql_query, self._connection)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThe duplicate check for the PostgreSQL table `postgres.public.customers` has been completed. There are **10 duplicate rows** detected in the table. Let me know if you need further assistance!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "======================================================================\n",
      "RESULT\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.agent.smart_planner import run_smart_dq_check\n",
    "\n",
    "result_1 = run_smart_dq_check(\"Check for duplicates in Snowflake PRODUCTS table\")\n",
    "\n",
    "result_2 = run_smart_dq_check(\"Check for duplicates in postgres CUSTOMERS table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6754b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Output:\n",
      "The duplicate check for the Snowflake table `PROD_SALES.DATA_MART_MANUFACTURING.PRODUCTS` has been completed. There are **626 duplicate rows** detected in the dataset. Let me know if you need further assistance or actions to address this issue.\n",
      "The duplicate check for the PostgreSQL table `postgres.public.customers` has been completed. There are **10 duplicate rows** detected in the table. Let me know if you need further assistance!\n"
     ]
    }
   ],
   "source": [
    "# Display the result\n",
    "print(\"Agent Output:\")\n",
    "print(result_1['output'])\n",
    "print(result_2['output'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-dq-agent-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
