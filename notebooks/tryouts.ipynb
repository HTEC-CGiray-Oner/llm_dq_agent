{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcf7ad65",
   "metadata": {},
   "source": [
    "# Smart Data Quality Agent - Demo Notebook\n",
    "\n",
    "## What This Notebook Does\n",
    "This notebook demonstrates the complete Smart DQ Check workflow:\n",
    "\n",
    "1. **Schema Indexing** - Automatically discovers and indexes your database tables (only runs when changes detected) Must run for first time\n",
    "2. **Smart Analysis** - Uses AI to understand your query and analyze the right tables  \n",
    "3. **Report Generation** - Creates comprehensive data quality reports in multiple formats (Markdown, HTML, JSON)\n",
    "\n",
    "## How to Use\n",
    "1. **First Time Setup**: The schema indexer will run automatically and discover your database tables\n",
    "2. **Run Analysis**: Enter a natural language query like \"check quality of customer data\" or \"analyze sales table duplicates\" or just hit enter if you want to run default query\n",
    "3. **Get Reports**: The system generates detailed reports saved to the `../reports` folder\n",
    "\n",
    "## What You'll Get in 3 different format .html .json and .md\n",
    "- Duplicate record analysis\n",
    "- Missing data (null values) assessment  \n",
    "- Statistical summaries and data profiling\n",
    "- Actionable recommendations for data quality improvements\n",
    "\n",
    "**Just run all cells in order **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596a0e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import re\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from src.retrieval.schema_indexer import SchemaIndexer\n",
    "from src.agent.smart_planner import run_smart_dq_check\n",
    "import src.reporting.report_templates\n",
    "import src.data_quality.checks\n",
    "import src.reporting.report_generator\n",
    "import src.agent.reporting_tools\n",
    "from src.reporting.report_templates import ReportTemplates\n",
    "from src.reporting.report_generator import DataQualityReportGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df062309",
   "metadata": {},
   "source": [
    "### Schema Indexing - Always rebuild from scratch to ensure fresh data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1a168d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî® Rebuilding index for SNOWFLAKE\n",
      "============================================================\n",
      " Connecting to Snowflake...\n",
      " Connecting to Snowflake...\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "‚úì Disconnected from Snowflake\n",
      "Auto-discovered 4 schemas on Snowflake: DATA_MART_FINANCE, DATA_MART_MANUFACTURING, DATA_MART_MARKETING, PUBLIC\n",
      "[1/4] INDEXING SCHEMA: DATA_MART_FINANCE\n",
      "‚úì Disconnected from Snowflake\n",
      "Auto-discovered 4 schemas on Snowflake: DATA_MART_FINANCE, DATA_MART_MANUFACTURING, DATA_MART_MARKETING, PUBLIC\n",
      "[1/4] INDEXING SCHEMA: DATA_MART_FINANCE\n",
      "\n",
      "Generating metadata documents for 2 tables...\n",
      "  [1/2] Processing INCOME_BAND...\n",
      "\n",
      "Generating metadata documents for 2 tables...\n",
      "  [1/2] Processing INCOME_BAND...\n",
      "  [2/2] Processing INVOICES...\n",
      "  [2/2] Processing INVOICES...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Indexing 2 table metadata documents...\n",
      "Indexed 2 tables from schema DATA_MART_FINANCE\n",
      "[2/4] INDEXING SCHEMA: DATA_MART_MANUFACTURING\n",
      "\n",
      "Generating metadata documents for 1 tables...\n",
      "  [1/1] Processing PRODUCTS...\n",
      "\n",
      "Generating metadata documents for 1 tables...\n",
      "  [1/1] Processing PRODUCTS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Indexing 1 table metadata documents...\n",
      "Indexed 1 tables from schema DATA_MART_MANUFACTURING\n",
      "[3/4] INDEXING SCHEMA: DATA_MART_MARKETING\n",
      "\n",
      "Generating metadata documents for 3 tables...\n",
      "  [1/3] Processing CALL_CENTER...\n",
      "\n",
      "Generating metadata documents for 3 tables...\n",
      "  [1/3] Processing CALL_CENTER...\n",
      "  [2/3] Processing CUSTOMERS...\n",
      "  [2/3] Processing CUSTOMERS...\n",
      "  [3/3] Processing SALES...\n",
      "  [3/3] Processing SALES...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Indexing 3 table metadata documents...\n",
      "Indexed 3 tables from schema DATA_MART_MARKETING\n",
      "[4/4] INDEXING SCHEMA: PUBLIC\n",
      "\n",
      "Generating metadata documents for 0 tables...\n",
      "No tables found in schema PUBLIC\n",
      " SCHEMA INDEX BUILT SUCCESSFULLY\n",
      "  - Collection: database_schemas\n",
      "  - Schemas indexed: 4\n",
      "  - Total tables indexed: 6\n",
      "   ‚úÖ Index rebuilt for snowflake\n",
      "\n",
      "üî® Rebuilding index for POSTGRES\n",
      "============================================================\n",
      "\n",
      "Generating metadata documents for 0 tables...\n",
      "No tables found in schema PUBLIC\n",
      " SCHEMA INDEX BUILT SUCCESSFULLY\n",
      "  - Collection: database_schemas\n",
      "  - Schemas indexed: 4\n",
      "  - Total tables indexed: 6\n",
      "   ‚úÖ Index rebuilt for snowflake\n",
      "\n",
      "üî® Rebuilding index for POSTGRES\n",
      "============================================================\n",
      " Connecting to postgres...\n",
      "‚úì Connected to PostgreSQL: stage_sales\n",
      "‚úì Disconnected from PostgreSQL\n",
      "Auto-discovered 1 schemas on postgres: public\n",
      "[1/1] INDEXING SCHEMA: public\n",
      " Connecting to postgres...\n",
      "‚úì Connected to PostgreSQL: stage_sales\n",
      "‚úì Disconnected from PostgreSQL\n",
      "Auto-discovered 1 schemas on postgres: public\n",
      "[1/1] INDEXING SCHEMA: public\n",
      "Discovering tables in stage_sales.public...\n",
      "‚úì Found 3 tables/views\n",
      "\n",
      "Generating metadata documents for 3 tables...\n",
      "  [1/3] Processing customers...\n",
      "Discovering tables in stage_sales.public...\n",
      "‚úì Found 3 tables/views\n",
      "Discovering tables in stage_sales.public...\n",
      "‚úì Found 3 tables/views\n",
      "\n",
      "Generating metadata documents for 3 tables...\n",
      "  [1/3] Processing customers...\n",
      "Discovering tables in stage_sales.public...\n",
      "‚úì Found 3 tables/views\n",
      "  [2/3] Processing invoices...\n",
      "Discovering tables in stage_sales.public...\n",
      "‚úì Found 3 tables/views\n",
      "  [2/3] Processing invoices...\n",
      "Discovering tables in stage_sales.public...\n",
      "‚úì Found 3 tables/views\n",
      "  [3/3] Processing products...\n",
      "Discovering tables in stage_sales.public...\n",
      "‚úì Found 3 tables/views\n",
      "  [3/3] Processing products...\n",
      "Discovering tables in stage_sales.public...\n",
      "‚úì Found 3 tables/views\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Indexing 3 table metadata documents...\n",
      "Indexed 3 tables from schema public\n",
      " SCHEMA INDEX BUILT SUCCESSFULLY\n",
      "  - Collection: database_schemas\n",
      "  - Schemas indexed: 1\n",
      "  - Total tables indexed: 3\n",
      "   ‚úÖ Index rebuilt for postgres\n",
      "\n",
      "üéâ SCHEMA INDEX REBUILD COMPLETE!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Load settings.yaml to read connector types dynamically\n",
    "with open('../config/settings.yaml', 'r') as f:\n",
    "    settings = yaml.safe_load(f)\n",
    "\n",
    "# Get connector types from settings.yaml\n",
    "connector_types = list(settings['connectors'].keys())\n",
    "\n",
    "print(f\"üöÄ REBUILDING SCHEMA INDEX FROM SCRATCH\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# First connector: recreate=True to start fresh\n",
    "# Subsequent connectors: recreate=False to preserve other connector data\n",
    "for i, ct in enumerate(connector_types):\n",
    "    print(f\"\\nüî® Rebuilding index for {ct.upper()}\")\n",
    "    print(f\"{'='*40}\")\n",
    "\n",
    "    # First connector recreates the entire index, others append to it\n",
    "    recreate_index = (i == 0)  # Only recreate on first connector\n",
    "\n",
    "    if recreate_index:\n",
    "        print(f\"   üóëÔ∏è  Starting fresh - recreating entire index\")\n",
    "    else:\n",
    "        print(f\"   ‚ûï Adding to existing index\")\n",
    "\n",
    "    indexer = SchemaIndexer(connector_type=ct)\n",
    "    indexer.build_schema_index(recreate=recreate_index)\n",
    "    print(f\"   ‚úÖ Index {'created' if recreate_index else 'updated'} for {ct}\")\n",
    "\n",
    "print(f\"\\nüéâ SCHEMA INDEX REBUILD COMPLETE!\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bb9e9e",
   "metadata": {},
   "source": [
    "## Enhanced Comprehensive Report Creation\n",
    "\n",
    "Generate comprehensive data quality reports with detailed duplicate counts, null analysis, and descriptive statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65981e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default query: Generate comprehensive DQ report for prod customers table\n",
      "Using query: create report for stage sales table\n",
      "\n",
      "======================================================================\n",
      "SMART DATA QUALITY CHECK\n",
      "======================================================================\n",
      "User Query: create report for stage sales table\n",
      "\n",
      "Step 1: Discovering relevant tables...\n",
      "----------------------------------------------------------------------\n",
      "Using query: create report for stage sales table\n",
      "\n",
      "======================================================================\n",
      "SMART DATA QUALITY CHECK\n",
      "======================================================================\n",
      "User Query: create report for stage sales table\n",
      "\n",
      "Step 1: Discovering relevant tables...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Number of requested results 20 is greater than number of elements in index 12, updating n_results = 12\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Number of requested results 20 is greater than number of elements in index 12, updating n_results = 12\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "# Get user input for the query with a default option\n",
    "default_query = \"Generate comprehensive DQ report for prod customers table\"\n",
    "print(f\"Default query: {default_query}\")\n",
    "user_query = input(\"Enter your DQ check query (or press Enter to use default): \").strip() or default_query\n",
    "print(f\"Using query: {user_query}\")\n",
    "\n",
    "comprehensive_report = run_smart_dq_check(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f053675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report content preview: No tables found with sufficient relevance (minimum 15% match required). Best match was 'PROD_SALES.DATA_MART_MARKETING.SALES' with only 0.9% relevance. Please try a more specific table name or check i...\n",
      "Smart DQ check failed due to low relevance scores.\n",
      "Skipping report generation - no valid table found for analysis.\n",
      "Try using a more specific table name in your query.\n",
      "\n",
      "Report generation failed: low_relevance\n",
      "Try using a more specific table name in your query.\n"
     ]
    }
   ],
   "source": [
    "# Use the new SmartDQReportProcessor to handle the complex report generation workflow\n",
    "from src.reporting.report_processor import SmartDQReportProcessor\n",
    "\n",
    "# Initialize the processor\n",
    "processor = SmartDQReportProcessor(reports_dir=\"../reports\")\n",
    "\n",
    "# Process the comprehensive report (handles validation, extraction, checks, and file generation)\n",
    "result = processor.process_comprehensive_report(comprehensive_report)\n",
    "\n",
    "# Display the final result\n",
    "if result['status'] == 'success':\n",
    "    print(f\" Generated files: {list(result['files_generated'].keys())}\")\n",
    "else:\n",
    "    print(f\"\\nReport generation failed: {result['reason']}\")\n",
    "    if result['reason'] == 'low_relevance':\n",
    "        print(\"Try using a more specific table name in your query.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-dq-agent-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
