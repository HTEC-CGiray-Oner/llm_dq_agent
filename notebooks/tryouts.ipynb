{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcf7ad65",
   "metadata": {},
   "source": [
    "# Smart Data Quality Agent - Demo Notebook\n",
    "\n",
    "## What This Notebook Does\n",
    "This notebook demonstrates the complete Smart DQ Check workflow with enhanced null analysis:\n",
    "\n",
    "1. **Schema Indexing** - Automatically discovers and indexes database tables (must run for first time) - No CDC logic applied as no requirement related defined on task description\n",
    "2. **Smart Analysis** - Uses AI to understand your query and analyze the right tables  \n",
    "3. **Enhanced Report Generation** - Creates comprehensive data quality reports with detailed null analysis in multiple formats\n",
    "4. **Fixed Null Analysis Issue**: Enhanced agent prompt to ensure detailed null values breakdown is always included\n",
    "5. **Complete Data Coverage**: Reports now show per-column null counts and percentages\n",
    "6. **Multi-Format Output**: All formats (Markdown, HTML, JSON) contain complete null analysis details\n",
    "\n",
    "## How to Use\n",
    "\n",
    "### **For Comprehensive Analysis:**\n",
    "1. **First Time Setup**: Run indexing cell to build schema index and discover your database tables\n",
    "2. **Run Analysis**: Following cell prompts for your query - try examples like:\n",
    "   - \"Generate comprehensive DQ report for prod customers table\"\n",
    "   - \"Create data quality report for production database invoices\"\n",
    "3. **Get Reports**: System generates detailed reports saved to `../reports/` in 3 formats (.html, .json, .md)\n",
    "\n",
    "### **For Single Quality Check Analysis:**\n",
    "1. **Run Schema Indexing** (same as above - required for all analysis types)\n",
    "2. **Choose Single Check Type**: Run the specific cells for focused analysis:\n",
    "   - **Duplicate-Only**: Run duplicate analysis cell for just duplicate detection\n",
    "   - **Null-Only**: Run null analysis cell for just missing values detection\n",
    "   - **Statistics-Only**: Use query \"Check statistics for [table]\" in comprehensive cell\n",
    "3. **Faster Execution**: Single checks run much faster than comprehensive analysis\n",
    "4. **Focused Reports**: Each single check creates a targeted report file (e.g., `duplicate_only_analysis.md`)\n",
    "\n",
    "### **When to Use Each Approach:**\n",
    "- **Comprehensive**: When you need complete data quality overview with all checks and in all report formats\n",
    "- **Single Check**: When investigating specific issues or need quick focused analysis\n",
    "\n",
    "### **Reports being saved under reports folder shows:**\n",
    "- **Duplicate Record Analysis** - Complete duplicate detection and counts\n",
    "- **Detailed Null Values Assessment** - Per-column breakdown with counts and percentages  \n",
    "- **Statistical Summaries** - Comprehensive data profiling with descriptive stats\n",
    "- **Actionable Recommendations** - Data quality improvement suggestions\n",
    "\n",
    "**Just run all cells in order and follow the prompts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "596a0e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import re\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from src.retrieval.schema_indexer import SchemaIndexer\n",
    "from src.agent.smart_planner import run_smart_dq_check\n",
    "import src.reporting.report_templates\n",
    "import src.data_quality.checks\n",
    "import src.reporting.report_generator\n",
    "import src.agent.reporting_tools\n",
    "import src.reporting.report_processor\n",
    "import src.reporting.report_templates\n",
    "import src.reporting.report_generator\n",
    "from src.reporting.report_processor import SmartDQReportProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df062309",
   "metadata": {},
   "source": [
    "## Schema Indexing \n",
    "\n",
    "Do not forget to run this cell for first time \n",
    "No need if there is no change in target schema & database (Incremental approach did not apply as not defined as requirement in task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac1a168d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " BUILDING SCHEMA INDEX FROM SCRATCH\n",
      "\n",
      " Rebuilding index for SNOWFLAKE\n",
      "  Starting fresh - recreating entire index\n",
      " Connecting to Snowflake...\n",
      " Connecting to Snowflake...\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "‚úì Disconnected from Snowflake\n",
      "Auto-discovered 4 schemas on Snowflake: DATA_MART_FINANCE, DATA_MART_MANUFACTURING, DATA_MART_MARKETING, PUBLIC\n",
      "[1/4] INDEXING SCHEMA: DATA_MART_FINANCE\n",
      "‚úì Disconnected from Snowflake\n",
      "Auto-discovered 4 schemas on Snowflake: DATA_MART_FINANCE, DATA_MART_MANUFACTURING, DATA_MART_MARKETING, PUBLIC\n",
      "[1/4] INDEXING SCHEMA: DATA_MART_FINANCE\n",
      "\n",
      "Generating metadata documents for 2 tables...\n",
      "  [1/2] Processing INCOME_BAND...\n",
      "\n",
      "Generating metadata documents for 2 tables...\n",
      "  [1/2] Processing INCOME_BAND...\n",
      "  [2/2] Processing INVOICES...\n",
      "  [2/2] Processing INVOICES...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Deleted existing collection: database_schemas\n",
      "\n",
      "Indexing 2 table metadata documents...\n",
      "Indexed 2 tables from schema DATA_MART_FINANCE\n",
      "[2/4] INDEXING SCHEMA: DATA_MART_MANUFACTURING\n",
      "Indexed 2 tables from schema DATA_MART_FINANCE\n",
      "[2/4] INDEXING SCHEMA: DATA_MART_MANUFACTURING\n",
      "\n",
      "Generating metadata documents for 1 tables...\n",
      "  [1/1] Processing PRODUCTS...\n",
      "\n",
      "Generating metadata documents for 1 tables...\n",
      "  [1/1] Processing PRODUCTS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Indexing 1 table metadata documents...\n",
      "Indexed 1 tables from schema DATA_MART_MANUFACTURING\n",
      "[3/4] INDEXING SCHEMA: DATA_MART_MARKETING\n",
      "\n",
      "Generating metadata documents for 3 tables...\n",
      "  [1/3] Processing CALL_CENTER...\n",
      "\n",
      "Generating metadata documents for 3 tables...\n",
      "  [1/3] Processing CALL_CENTER...\n",
      "  [2/3] Processing CUSTOMERS...\n",
      "  [2/3] Processing CUSTOMERS...\n",
      "  [3/3] Processing SALES...\n",
      "  [3/3] Processing SALES...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Indexing 3 table metadata documents...\n",
      "Indexed 3 tables from schema DATA_MART_MARKETING\n",
      "[4/4] INDEXING SCHEMA: PUBLIC\n",
      "\n",
      "Generating metadata documents for 0 tables...\n",
      "No tables found in schema PUBLIC\n",
      " SCHEMA INDEX BUILT SUCCESSFULLY\n",
      "  - Collection: database_schemas\n",
      "  - Schemas indexed: 4\n",
      "  - Total tables indexed: 6\n",
      "   Index created for snowflake\n",
      "\n",
      " Rebuilding index for POSTGRES\n",
      "  Adding to existing index\n",
      "\n",
      "Generating metadata documents for 0 tables...\n",
      "No tables found in schema PUBLIC\n",
      " SCHEMA INDEX BUILT SUCCESSFULLY\n",
      "  - Collection: database_schemas\n",
      "  - Schemas indexed: 4\n",
      "  - Total tables indexed: 6\n",
      "   Index created for snowflake\n",
      "\n",
      " Rebuilding index for POSTGRES\n",
      "  Adding to existing index\n",
      " Connecting to postgres...\n",
      " Connecting to postgres...\n",
      "‚úì Connected to PostgreSQL: stage_sales\n",
      "‚úì Disconnected from PostgreSQL\n",
      "Auto-discovered 1 schemas on postgres: public\n",
      "[1/1] INDEXING SCHEMA: public\n",
      "Discovering tables in stage_sales.public...\n",
      "‚úì Found 3 tables/views\n",
      "\n",
      "Generating metadata documents for 3 tables...\n",
      "  [1/3] Processing customers...\n",
      "‚úì Connected to PostgreSQL: stage_sales\n",
      "‚úì Disconnected from PostgreSQL\n",
      "Auto-discovered 1 schemas on postgres: public\n",
      "[1/1] INDEXING SCHEMA: public\n",
      "Discovering tables in stage_sales.public...\n",
      "‚úì Found 3 tables/views\n",
      "\n",
      "Generating metadata documents for 3 tables...\n",
      "  [1/3] Processing customers...\n",
      "Discovering tables in stage_sales.public...\n",
      "‚úì Found 3 tables/views\n",
      "Discovering tables in stage_sales.public...\n",
      "‚úì Found 3 tables/views\n",
      "  [2/3] Processing invoices...\n",
      "Discovering tables in stage_sales.public...\n",
      "‚úì Found 3 tables/views\n",
      "  [2/3] Processing invoices...\n",
      "Discovering tables in stage_sales.public...\n",
      "‚úì Found 3 tables/views\n",
      "  [3/3] Processing products...\n",
      "Discovering tables in stage_sales.public...\n",
      "‚úì Found 3 tables/views\n",
      "  [3/3] Processing products...\n",
      "Discovering tables in stage_sales.public...\n",
      "‚úì Found 3 tables/views\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Indexing 3 table metadata documents...\n",
      "Indexed 3 tables from schema public\n",
      " SCHEMA INDEX BUILT SUCCESSFULLY\n",
      "  - Collection: database_schemas\n",
      "  - Schemas indexed: 1\n",
      "  - Total tables indexed: 3\n",
      "   Index updated for postgres\n",
      "\n",
      " SCHEMA INDEX REBUILD COMPLETE!\n"
     ]
    }
   ],
   "source": [
    "# Load settings.yaml to read connector types dynamically\n",
    "with open('../config/settings.yaml', 'r') as f:\n",
    "    settings = yaml.safe_load(f)\n",
    "\n",
    "# Get connector types from settings.yaml\n",
    "connector_types = list(settings['connectors'].keys())\n",
    "\n",
    "print(f\" BUILDING SCHEMA INDEX FROM SCRATCH\")\n",
    "\n",
    "# First connector: recreate=True\n",
    "# Subsequent connectors: recreate=False to preserve other connector data\n",
    "for i, ct in enumerate(connector_types):\n",
    "    print(f\"\\n Rebuilding index for {ct.upper()}\")\n",
    "\n",
    "    # First connector recreates the entire index, others append to it\n",
    "    recreate_index = (i == 0)  # Only recreate on first connector\n",
    "\n",
    "    if recreate_index:\n",
    "        print(f\"  Starting fresh - recreating entire index\")\n",
    "    else:\n",
    "        print(f\"  Adding to existing index\")\n",
    "\n",
    "    indexer = SchemaIndexer(connector_type=ct)\n",
    "    indexer.build_schema_index(recreate=recreate_index)\n",
    "    print(f\"   Index {'created' if recreate_index else 'updated'} for {ct}\")\n",
    "\n",
    "print(f\"\\n SCHEMA INDEX REBUILD COMPLETE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bb9e9e",
   "metadata": {},
   "source": [
    "## Enhanced Comprehensive Report Creation\n",
    "\n",
    "Generate comprehensive data quality reports with detailed duplicate counts, null analysis, and descriptive statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee612e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Running DQ check for query: Analyze staging analytics data quality\n",
      "\n",
      "======================================================================\n",
      "SMART DATA QUALITY CHECK\n",
      "======================================================================\n",
      "User Query: Analyze staging analytics data quality\n",
      "\n",
      "Step 1: Discovering relevant tables...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Number of requested results 20 is greater than number of elements in index 9, updating n_results = 9\n",
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Number of requested results 20 is greater than number of elements in index 9, updating n_results = 9\n",
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report output: No relevant tables found. Please ensure the schema index is built. Run: python src/retrieval/schema_indexer.py\n",
      "Smart DQ check failed due to low relevance scores.\n",
      "Skipping report generation - no valid table found for analysis.\n",
      "Try using a more specific table name in your query.\n",
      "0, Report processing complete.\n",
      "\n",
      " Running DQ check for query: Create comprehensive report of UNKNOWN table data quality for staging database\n",
      "\n",
      "======================================================================\n",
      "SMART DATA QUALITY CHECK\n",
      "======================================================================\n",
      "User Query: Create comprehensive report of UNKNOWN table data quality for staging database\n",
      "\n",
      "Step 1: Discovering relevant tables...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Number of requested results 20 is greater than number of elements in index 9, updating n_results = 9\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Number of requested results 20 is greater than number of elements in index 9, updating n_results = 9\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report output: No relevant tables found. Please ensure the schema index is built. Run: python src/retrieval/schema_indexer.py\n",
      "Smart DQ check failed due to low relevance scores.\n",
      "Skipping report generation - no valid table found for analysis.\n",
      "Try using a more specific table name in your query.\n",
      "1, Report processing complete.\n",
      "\n",
      " Running DQ check for query: Generate comprehensive DQ report for staging sales table in postgres\n",
      "\n",
      "======================================================================\n",
      "SMART DATA QUALITY CHECK\n",
      "======================================================================\n",
      "User Query: Generate comprehensive DQ report for staging sales table in postgres\n",
      "\n",
      "Step 1: Discovering relevant tables...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Number of requested results 20 is greater than number of elements in index 9, updating n_results = 9\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Number of requested results 20 is greater than number of elements in index 9, updating n_results = 9\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 3 relevant table(s) (‚â•5% relevance):\n",
      "\n",
      "  1. [POSTGRES] stage_sales.public.products\n",
      "     Relevance: 16.67% ‚úì\n",
      "\n",
      "  2. [SNOWFLAKE] PROD_SALES.DATA_MART_MARKETING.SALES\n",
      "     Relevance: 12.63% ‚úì\n",
      "\n",
      "  3. [POSTGRES] stage_sales.public.invoices\n",
      "     Relevance: 10.19% ‚úì\n",
      "\n",
      "Step 2: Building context for agent...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Step 3: Running agent with discovered tables...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `generate_comprehensive_dq_report` with `{'dataset_id': 'stage_sales.public.products', 'connector_type': 'postgres', 'output_format': 'markdown'}`\n",
      "\n",
      "\n",
      "\u001b[0mRunning duplicates check...\n",
      "--- Loading data for: stage_sales.public.products using POSTGRES connector ---\n",
      "‚úì Connected to PostgreSQL: stage_sales\n",
      "Executing query: SELECT * FROM stage_sales.public.products\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `generate_comprehensive_dq_report` with `{'dataset_id': 'stage_sales.public.products', 'connector_type': 'postgres', 'output_format': 'markdown'}`\n",
      "\n",
      "\n",
      "\u001b[0mRunning duplicates check...\n",
      "--- Loading data for: stage_sales.public.products using POSTGRES connector ---\n",
      "‚úì Connected to PostgreSQL: stage_sales\n",
      "Executing query: SELECT * FROM stage_sales.public.products\n",
      "‚úì Loaded 30000 rows from PostgreSQL\n",
      "‚úì Disconnected from PostgreSQL\n",
      "Running null_values check...\n",
      "--- Loading data for: stage_sales.public.products using POSTGRES connector ---\n",
      "‚úì Connected to PostgreSQL: stage_sales\n",
      "Executing query: SELECT * FROM stage_sales.public.products\n",
      "‚úì Loaded 30000 rows from PostgreSQL\n",
      "‚úì Disconnected from PostgreSQL\n",
      "Running null_values check...\n",
      "--- Loading data for: stage_sales.public.products using POSTGRES connector ---\n",
      "‚úì Connected to PostgreSQL: stage_sales\n",
      "Executing query: SELECT * FROM stage_sales.public.products\n",
      "‚úì Loaded 30000 rows from PostgreSQL\n",
      "‚úì Disconnected from PostgreSQL\n",
      "Running descriptive_stats check...\n",
      "--- Loading data for: stage_sales.public.products using POSTGRES connector ---\n",
      "‚úì Loaded 30000 rows from PostgreSQL\n",
      "‚úì Disconnected from PostgreSQL\n",
      "Running descriptive_stats check...\n",
      "--- Loading data for: stage_sales.public.products using POSTGRES connector ---\n",
      "‚úì Connected to PostgreSQL: stage_sales\n",
      "Executing query: SELECT * FROM stage_sales.public.products\n",
      "‚úì Connected to PostgreSQL: stage_sales\n",
      "Executing query: SELECT * FROM stage_sales.public.products\n",
      "‚úì Loaded 30000 rows from PostgreSQL\n",
      "‚úì Disconnected from PostgreSQL\n",
      "‚úì Converted 'product_id' to categorical for descriptive statistics\n",
      "\u001b[33;1m\u001b[1;3m{'dataset_id': 'stage_sales.public.products', 'connector_type': 'postgres', 'report_format': 'markdown', 'report_content': '# Data Quality Assessment Report\\n\\n## Dataset Information\\n- **Dataset**: `stage_sales.public.products`\\n- **Connector**: POSTGRES\\n- **Assessment Date**: 2025-11-27 13:50:22\\n- **Total Checks**: 3\\n\\n## Executive Summary\\n- ‚úÖ **Passed**: 1 checks\\n- ‚ùå **Failed**: 2 checks\\n- üö´ **Errors**: 0 checks\\n\\n---\\n\\n## Detailed Check Results\\n\\n### ‚ùå Duplicates\\n\\n- **Status**: ERROR\\n- **Error**: Unknown error\\n\\n### ‚úÖ Null Values\\n\\n- **Status**: FAIL\\n- **Dataset Size**: 30,000 rows √ó 25 columns\\n- **Columns with Missing Data**: 4 out of 25 columns\\n- **Missing Data Coverage**: 16.0% of columns affected\\n\\n**Detailed Null Analysis:**\\n- `supplier`: 5,400 nulls (18.0%)\\n- `description`: 4,500 nulls (15.0%)\\n- `brand`: 3,600 nulls (12.0%)\\n- `weight`: 2,915 nulls (9.7%)\\n\\n### ‚úÖ Descriptive Stats\\n\\n- **Status**: PASS (Statistics Generated)\\\\n- **Columns Analyzed**: 25 columns\\\\n\\\\n**üìä Complete Statistical Summary:**\\\\n\\\\n| Column | Count | Mean | Std | Min | 25% | 50% | 75% | Max | Unique | Top | Freq |\\\\n|--------|-------|------|-----|-----|-----|-----|-----|-----|--------|-----|------|\\\\n| `product_id` | 30,000.00 | - | - | - | - | - | - | - | 27,600.00 | 24,390.00 | 4.00 |\\\\n| `sku` | 30,000 | - | - | - | - | - | - | - | 27169 | SKU-465741 | 5 |\\\\n| `product_name` | 30,000 | - | - | - | - | - | - | - | 27212 | Automated multi | 4 |\\\\n| `description` | 25,500 | - | - | - | - | - | - | - | 23748 | Mrs blood yard  | 4 |\\\\n| `category` | 30,000 | - | - | - | - | - | - | - | 10 | Office Supplies | 3,096 |\\\\n| `subcategory` | 30,000 | - | - | - | - | - | - | - | 971 | Media | 52 |\\\\n| `brand` | 26,400 | - | - | - | - | - | - | - | 19489 | Smith LLC | 39 |\\\\n| `supplier` | 24,600 | - | - | - | - | - | - | - | 18318 | Smith LLC | 40 |\\\\n| `price` | 30,000.00 | 251.41 | 376.93 | -499.80 | 44.55 | 125.36 | 297.94 | 1,999.78 | - | - | - |\\\\n| `cost` | 30,000.00 | 222.11 | 293.43 | 1.54 | 41.97 | 108.33 | 258.52 | 1,789.46 | - | - | - |\\\\n| `currency` | 30,000 | - | - | - | - | - | - | - | 3 | GBP | 10,064 |\\\\n| `stock_quantity` | 30,000.00 | 460.02 | 351.94 | -999.00 | 215.00 | 480.00 | 743.00 | 1,000.00 | - | - | - |\\\\n| `reorder_level` | 30,000.00 | 55.15 | 26.39 | 10.00 | 32.00 | 55.00 | 78.00 | 100.00 | - | - | - |\\\\n| `weight` | 27,085.00 | 33,252.89 | 179,232.13 | 0.10 | 12.89 | 25.88 | 38.57 | 999,999.99 | - | - | - |\\\\n| `dimensions` | 30,000 | - | - | - | - | - | - | - | 27138 | 71x75x85 cm | 4 |\\\\n| `color` | 30,000 | - | - | - | - | - | - | - | 140 | LightSlateGray | 256 |\\\\n| `size` | 30,000 | - | - | - | - | - | - | - | 7 | S | 4,395 |\\\\n| `material` | 30,000 | - | - | - | - | - | - | - | 7 | Metal | 4,411 |\\\\n| `rating` | 30,000.00 | 5.60 | 12.80 | 1.00 | 2.00 | 3.10 | 4.10 | 100.00 | - | - | - |\\\\n| `review_count` | 30,000.00 | 2,488.51 | 1,446.80 | 0.00 | 1,231.00 | 2,493.00 | 3,725.00 | 5,000.00 | - | - | - |\\\\n| `is_available` | 30,000 | - | - | - | - | - | - | - | 2 | True | 29,977 |\\\\n| `is_featured` | 30,000 | - | - | - | - | - | - | - | 2 | True | 15,012 |\\\\n| `discount_percentage` | 30,000.00 | 15.01 | 8.65 | 0.00 | 7.60 | 15.10 | 22.50 | 30.00 | - | - | - |\\\\n| `created_date` | 30,000 | - | - | - | - | - | - | - | 1096 | 2025-06-02 | 49 |\\\\n| `last_updated` | 30,000 | - | - | - | - | - | - | - | 1056 | 2025-11-18 | 211 |\\\\n\\n---\\n\\n## Recommendations\\n\\n1. **Establish Data Quality Framework**\\n   - Only 33% of checks passed. Consider implementing: 1) Data validation at ingestion, 2) Regular quality monitoring, 3) Data stewardship roles, 4) Quality metrics dashboards.\\n   - *Priority*: High\\n\\n2. **Implement Null Handling Strategy**\\n   - Columns `supplier`, `description`, `brand` have 5-20% null values. Consider implementing NOT NULL constraints, data validation rules, or imputation strategies based on business logic.\\n   - *Priority*: Medium\\n\\n3. **Investigate High Variability in weight**\\n   - Column `weight` has high variability (CV=5.39). Review for outliers, data entry errors, or consider data transformation/normalization techniques.\\n   - *Priority*: Low\\n\\n4. **Investigate High Variability in rating**\\n   - Column `rating` has high variability (CV=2.29). Review for outliers, data entry errors, or consider data transformation/normalization techniques.\\n   - *Priority*: Low\\n\\n5. **Data Documentation and Profiling**\\n   - Dataset has 25 columns. Consider creating data dictionaries, establishing column-level monitoring, and implementing regular statistical profiling to track data drift over time.\\n   - *Priority*: Low\\n\\n---\\n\\n## Report Generation\\n- **Generated by**: LLM Data Quality Agent\\n- **Generation Time**: 2025-11-27 13:50:22\\n- **Report Format**: Markdown\\n\\n*This report was automatically generated. Please review recommendations and take appropriate action.*\\n', 'summary': {'total_checks': 3, 'passed_checks': 1, 'failed_checks': 2, 'error_checks': 0, 'pass_rate': '33.3%'}, 'recommendations_count': 5, 'status': 'success'}\u001b[0m‚úì Loaded 30000 rows from PostgreSQL\n",
      "‚úì Disconnected from PostgreSQL\n",
      "‚úì Converted 'product_id' to categorical for descriptive statistics\n",
      "\u001b[33;1m\u001b[1;3m{'dataset_id': 'stage_sales.public.products', 'connector_type': 'postgres', 'report_format': 'markdown', 'report_content': '# Data Quality Assessment Report\\n\\n## Dataset Information\\n- **Dataset**: `stage_sales.public.products`\\n- **Connector**: POSTGRES\\n- **Assessment Date**: 2025-11-27 13:50:22\\n- **Total Checks**: 3\\n\\n## Executive Summary\\n- ‚úÖ **Passed**: 1 checks\\n- ‚ùå **Failed**: 2 checks\\n- üö´ **Errors**: 0 checks\\n\\n---\\n\\n## Detailed Check Results\\n\\n### ‚ùå Duplicates\\n\\n- **Status**: ERROR\\n- **Error**: Unknown error\\n\\n### ‚úÖ Null Values\\n\\n- **Status**: FAIL\\n- **Dataset Size**: 30,000 rows √ó 25 columns\\n- **Columns with Missing Data**: 4 out of 25 columns\\n- **Missing Data Coverage**: 16.0% of columns affected\\n\\n**Detailed Null Analysis:**\\n- `supplier`: 5,400 nulls (18.0%)\\n- `description`: 4,500 nulls (15.0%)\\n- `brand`: 3,600 nulls (12.0%)\\n- `weight`: 2,915 nulls (9.7%)\\n\\n### ‚úÖ Descriptive Stats\\n\\n- **Status**: PASS (Statistics Generated)\\\\n- **Columns Analyzed**: 25 columns\\\\n\\\\n**üìä Complete Statistical Summary:**\\\\n\\\\n| Column | Count | Mean | Std | Min | 25% | 50% | 75% | Max | Unique | Top | Freq |\\\\n|--------|-------|------|-----|-----|-----|-----|-----|-----|--------|-----|------|\\\\n| `product_id` | 30,000.00 | - | - | - | - | - | - | - | 27,600.00 | 24,390.00 | 4.00 |\\\\n| `sku` | 30,000 | - | - | - | - | - | - | - | 27169 | SKU-465741 | 5 |\\\\n| `product_name` | 30,000 | - | - | - | - | - | - | - | 27212 | Automated multi | 4 |\\\\n| `description` | 25,500 | - | - | - | - | - | - | - | 23748 | Mrs blood yard  | 4 |\\\\n| `category` | 30,000 | - | - | - | - | - | - | - | 10 | Office Supplies | 3,096 |\\\\n| `subcategory` | 30,000 | - | - | - | - | - | - | - | 971 | Media | 52 |\\\\n| `brand` | 26,400 | - | - | - | - | - | - | - | 19489 | Smith LLC | 39 |\\\\n| `supplier` | 24,600 | - | - | - | - | - | - | - | 18318 | Smith LLC | 40 |\\\\n| `price` | 30,000.00 | 251.41 | 376.93 | -499.80 | 44.55 | 125.36 | 297.94 | 1,999.78 | - | - | - |\\\\n| `cost` | 30,000.00 | 222.11 | 293.43 | 1.54 | 41.97 | 108.33 | 258.52 | 1,789.46 | - | - | - |\\\\n| `currency` | 30,000 | - | - | - | - | - | - | - | 3 | GBP | 10,064 |\\\\n| `stock_quantity` | 30,000.00 | 460.02 | 351.94 | -999.00 | 215.00 | 480.00 | 743.00 | 1,000.00 | - | - | - |\\\\n| `reorder_level` | 30,000.00 | 55.15 | 26.39 | 10.00 | 32.00 | 55.00 | 78.00 | 100.00 | - | - | - |\\\\n| `weight` | 27,085.00 | 33,252.89 | 179,232.13 | 0.10 | 12.89 | 25.88 | 38.57 | 999,999.99 | - | - | - |\\\\n| `dimensions` | 30,000 | - | - | - | - | - | - | - | 27138 | 71x75x85 cm | 4 |\\\\n| `color` | 30,000 | - | - | - | - | - | - | - | 140 | LightSlateGray | 256 |\\\\n| `size` | 30,000 | - | - | - | - | - | - | - | 7 | S | 4,395 |\\\\n| `material` | 30,000 | - | - | - | - | - | - | - | 7 | Metal | 4,411 |\\\\n| `rating` | 30,000.00 | 5.60 | 12.80 | 1.00 | 2.00 | 3.10 | 4.10 | 100.00 | - | - | - |\\\\n| `review_count` | 30,000.00 | 2,488.51 | 1,446.80 | 0.00 | 1,231.00 | 2,493.00 | 3,725.00 | 5,000.00 | - | - | - |\\\\n| `is_available` | 30,000 | - | - | - | - | - | - | - | 2 | True | 29,977 |\\\\n| `is_featured` | 30,000 | - | - | - | - | - | - | - | 2 | True | 15,012 |\\\\n| `discount_percentage` | 30,000.00 | 15.01 | 8.65 | 0.00 | 7.60 | 15.10 | 22.50 | 30.00 | - | - | - |\\\\n| `created_date` | 30,000 | - | - | - | - | - | - | - | 1096 | 2025-06-02 | 49 |\\\\n| `last_updated` | 30,000 | - | - | - | - | - | - | - | 1056 | 2025-11-18 | 211 |\\\\n\\n---\\n\\n## Recommendations\\n\\n1. **Establish Data Quality Framework**\\n   - Only 33% of checks passed. Consider implementing: 1) Data validation at ingestion, 2) Regular quality monitoring, 3) Data stewardship roles, 4) Quality metrics dashboards.\\n   - *Priority*: High\\n\\n2. **Implement Null Handling Strategy**\\n   - Columns `supplier`, `description`, `brand` have 5-20% null values. Consider implementing NOT NULL constraints, data validation rules, or imputation strategies based on business logic.\\n   - *Priority*: Medium\\n\\n3. **Investigate High Variability in weight**\\n   - Column `weight` has high variability (CV=5.39). Review for outliers, data entry errors, or consider data transformation/normalization techniques.\\n   - *Priority*: Low\\n\\n4. **Investigate High Variability in rating**\\n   - Column `rating` has high variability (CV=2.29). Review for outliers, data entry errors, or consider data transformation/normalization techniques.\\n   - *Priority*: Low\\n\\n5. **Data Documentation and Profiling**\\n   - Dataset has 25 columns. Consider creating data dictionaries, establishing column-level monitoring, and implementing regular statistical profiling to track data drift over time.\\n   - *Priority*: Low\\n\\n---\\n\\n## Report Generation\\n- **Generated by**: LLM Data Quality Agent\\n- **Generation Time**: 2025-11-27 13:50:22\\n- **Report Format**: Markdown\\n\\n*This report was automatically generated. Please review recommendations and take appropriate action.*\\n', 'summary': {'total_checks': 3, 'passed_checks': 1, 'failed_checks': 2, 'error_checks': 0, 'pass_rate': '33.3%'}, 'recommendations_count': 5, 'status': 'success'}\u001b[0m\u001b[32;1m\u001b[1;3m### Comprehensive Data Quality Report for `stage_sales.public.products` (Postgres)\n",
      "\n",
      "---\n",
      "\n",
      "#### **Dataset Information**\n",
      "- **Dataset**: `stage_sales.public.products`\n",
      "- **Connector**: POSTGRES\n",
      "- **Assessment Date**: 2025-11-27\n",
      "- **Total Checks**: 3\n",
      "\n",
      "---\n",
      "\n",
      "### **Executive Summary**\n",
      "- ‚úÖ **Passed**: 1 checks\n",
      "- ‚ùå **Failed**: 2 checks\n",
      "- üö´ **Errors**: 0 checks\n",
      "\n",
      "---\n",
      "\n",
      "### **Detailed Check Results**\n",
      "\n",
      "#### ‚ùå **Duplicates**\n",
      "- **Status**: ERROR\n",
      "- **Error**: Unknown error\n",
      "\n",
      "---\n",
      "\n",
      "#### ‚úÖ **Null Values**\n",
      "- **Status**: FAIL\n",
      "- **Dataset Size**: 30,000 rows √ó 25 columns\n",
      "- **Columns with Missing Data**: 4 out of 25 columns\n",
      "- **Missing Data Coverage**: 16.0% of columns affected\n",
      "\n",
      "**Detailed Null Analysis**:\n",
      "- `supplier`: 5,400 nulls (18.0%)\n",
      "- `description`: 4,500 nulls (15.0%)\n",
      "- `brand`: 3,600 nulls (12.0%)\n",
      "- `weight`: 2,915 nulls (9.7%)\n",
      "\n",
      "---\n",
      "\n",
      "#### ‚úÖ **Descriptive Stats**\n",
      "- **Status**: PASS (Statistics Generated)\n",
      "- **Columns Analyzed**: 25 columns\n",
      "\n",
      "**üìä Complete Statistical Summary**:\n",
      "\n",
      "| Column            | Count     | Mean     | Std      | Min      | 25%      | 50%      | 75%      | Max       | Unique   | Top              | Freq |\n",
      "|-------------------|-----------|----------|----------|----------|----------|----------|----------|-----------|----------|------------------|------|\n",
      "| `product_id`      | 30,000.00 | -        | -        | -        | -        | -        | -        | -         | 27,600.00 | 24,390.00        | 4    |\n",
      "| `sku`             | 30,000    | -        | -        | -        | -        | -        | -        | -         | 27,169   | SKU-465741       | 5    |\n",
      "| `product_name`    | 30,000    | -        | -        | -        | -        | -        | -        | -         | 27,212   | Automated multi  | 4    |\n",
      "| `description`     | 25,500    | -        | -        | -        | -        | -        | -        | -         | 23,748   | Mrs blood yard   | 4    |\n",
      "| `category`        | 30,000    | -        | -        | -        | -        | -        | -        | -         | 10       | Office Supplies  | 3,096|\n",
      "| `subcategory`     | 30,000    | -        | -        | -        | -        | -        | -        | -         | 971      | Media            | 52   |\n",
      "| `brand`           | 26,400    | -        | -        | -        | -        | -        | -        | -         | 19,489   | Smith LLC        | 39   |\n",
      "| `supplier`        | 24,600    | -        | -        | -        | -        | -        | -        | -         | 18,318   | Smith LLC        | 40   |\n",
      "| `price`           | 30,000.00 | 251.41   | 376.93   | -499.80  | 44.55    | 125.36   | 297.94   | 1,999.78  | -        | -                | -    |\n",
      "| `cost`            | 30,000.00 | 222.11   | 293.43   | 1.54     | 41.97    | 108.33   | 258.52   | 1,789.46  | -        | -                | -    |\n",
      "| `currency`        | 30,000    | -        | -        | -        | -        | -        | -        | -         | 3        | GBP              | 10,064|\n",
      "| `stock_quantity`  | 30,000.00 | 460.02   | 351.94   | -999.00  | 215.00   | 480.00   | 743.00   | 1,000.00  | -        | -                | -    |\n",
      "| `reorder_level`   | 30,000.00 | 55.15    | 26.39    | 10.00    | 32.00    | 55.00    | 78.00    | 100.00    | -        | -                | -    |\n",
      "| `weight`          | 27,085.00 | 33,252.89| 179,232.13| 0.10    | 12.89    | 25.88    | 38.57    | 999,999.99| -        | -                | -    |\n",
      "| `dimensions`      | 30,000    | -        | -        | -        | -        | -        | -        | -         | 27,138   | 71x75x85 cm      | 4    |\n",
      "| `color`           | 30,000    | -        | -        | -        | -        | -        | -        | -         | 140      | LightSlateGray   | 256  |\n",
      "| `size`            | 30,000    | -        | -        | -        | -        | -        | -        | -         | 7        | S                | 4,395|\n",
      "| `material`        | 30,000    | -        | -        | -        | -        | -        | -        | -         | 7        | Metal            | 4,411|\n",
      "| `rating`          | 30,000.00 | 5.60     | 12.80    | 1.00     | 2.00     | 3.10     | 4.10     | 100.00    | -        | -                | -    |\n",
      "| `review_count`    | 30,000.00 | 2,488.51 | 1,446.80 | 0.00     | 1,231.00 | 2,493.00 | 3,725.00 | 5,000.00  | -        | -                | -    |\n",
      "| `is_available`    | 30,000    | -        | -        | -        | -        | -        | -        | -         | 2        | True             | 29,977|\n",
      "| `is_featured`     | 30,000    | -        | -        | -        | -        | -        | -        | -         | 2        | True             | 15,012|\n",
      "| `discount_percentage` | 30,000.00 | 15.01 | 8.65    | 0.00     | 7.60     | 15.10    | 22.50    | 30.00     | -        | -                | -    |\n",
      "| `created_date`    | 30,000    | -        | -        | -        | -        | -        | -        | -         | 1,096    | 2025-06-02       | 49   |\n",
      "| `last_updated`    | 30,000    | -        | -        | -        | -        | -        | -        | -         | 1,056    | 2025-11-18       | 211  |\n",
      "\n",
      "---\n",
      "\n",
      "### **Recommendations**\n",
      "1. **Establish Data Quality Framework**\n",
      "   - Only 33% of checks passed. Consider implementing: 1) Data validation at ingestion, 2) Regular quality monitoring, 3) Data stewardship roles, 4) Quality metrics dashboards.\n",
      "   - *Priority*: High\n",
      "\n",
      "2. **Implement Null Handling Strategy**\n",
      "   - Columns `supplier`, `description`, `brand` have 5-20% null values. Consider implementing NOT NULL constraints, data validation rules, or imputation strategies based on business logic.\n",
      "   - *Priority*: Medium\n",
      "\n",
      "3. **Investigate High Variability in `weight`**\n",
      "   - Column `weight` has high variability (CV=5.39). Review for outliers, data entry errors, or consider data transformation/normalization techniques.\n",
      "   - *Priority*: Low\n",
      "\n",
      "4. **Investigate High Variability in `rating`**\n",
      "   - Column `rating` has high variability (CV=2.29). Review for outliers, data entry errors, or consider data transformation/normalization techniques.\n",
      "   - *Priority*: Low\n",
      "\n",
      "5. **Data Documentation and Profiling**\n",
      "   - Dataset has 25 columns. Consider creating data dictionaries, establishing column-level monitoring, and implementing regular statistical profiling to track data drift over time.\n",
      "   - *Priority*: Low\n",
      "\n",
      "---\n",
      "\n",
      "**Generated by**: LLM Data Quality Agent  \n",
      "**Generation Time**: 2025-11-27  \n",
      "**Report Format**: Markdown  \n",
      "\n",
      "*This report was automatically generated. Please review recommendations and take appropriate action.*\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "======================================================================\n",
      "RESULT\n",
      "======================================================================\n",
      "\n",
      "Report output: ### Comprehensive Data Quality Report for `stage_sales.public.products` (Postgres)\n",
      "\n",
      "---\n",
      "\n",
      "#### **Dataset Information**\n",
      "- **Dataset**: `stage_sales.public.products`\n",
      "- **Connector**: POSTGRES\n",
      "- **Assessment Date**: 2025-11-27\n",
      "- **Total Checks**: 3\n",
      "\n",
      "---\n",
      "\n",
      "### **Executive Summary**\n",
      "- ‚úÖ **Passed**: 1 checks\n",
      "- ‚ùå **Failed**: 2 checks\n",
      "- üö´ **Errors**: 0 checks\n",
      "\n",
      "---\n",
      "\n",
      "### **Detailed Check Results**\n",
      "\n",
      "#### ‚ùå **Duplicates**\n",
      "- **Status**: ERROR\n",
      "- **Error**: Unknown error\n",
      "\n",
      "---\n",
      "\n",
      "#### ‚úÖ **Null Values**\n",
      "- **Status**: FAIL\n",
      "- **Dataset Size**: 30,000 rows √ó 25 columns\n",
      "- **Columns with Missing Data**: 4 out of 25 columns\n",
      "- **Missing Data Coverage**: 16.0% of columns affected\n",
      "\n",
      "**Detailed Null Analysis**:\n",
      "- `supplier`: 5,400 nulls (18.0%)\n",
      "- `description`: 4,500 nulls (15.0%)\n",
      "- `brand`: 3,600 nulls (12.0%)\n",
      "- `weight`: 2,915 nulls (9.7%)\n",
      "\n",
      "---\n",
      "\n",
      "#### ‚úÖ **Descriptive Stats**\n",
      "- **Status**: PASS (Statistics Generated)\n",
      "- **Columns Analyzed**: 25 columns\n",
      "\n",
      "**üìä Complete Statistical Summary**:\n",
      "\n",
      "| Column            | Count     | Mean     | Std      | Min      | 25%      | 50%      | 75%      | Max       | Unique   | Top              | Freq |\n",
      "|-------------------|-----------|----------|----------|----------|----------|----------|----------|-----------|----------|------------------|------|\n",
      "| `product_id`      | 30,000.00 | -        | -        | -        | -        | -        | -        | -         | 27,600.00 | 24,390.00        | 4    |\n",
      "| `sku`             | 30,000    | -        | -        | -        | -        | -        | -        | -         | 27,169   | SKU-465741       | 5    |\n",
      "| `product_name`    | 30,000    | -        | -        | -        | -        | -        | -        | -         | 27,212   | Automated multi  | 4    |\n",
      "| `description`     | 25,500    | -        | -        | -        | -        | -        | -        | -         | 23,748   | Mrs blood yard   | 4    |\n",
      "| `category`        | 30,000    | -        | -        | -        | -        | -        | -        | -         | 10       | Office Supplies  | 3,096|\n",
      "| `subcategory`     | 30,000    | -        | -        | -        | -        | -        | -        | -         | 971      | Media            | 52   |\n",
      "| `brand`           | 26,400    | -        | -        | -        | -        | -        | -        | -         | 19,489   | Smith LLC        | 39   |\n",
      "| `supplier`        | 24,600    | -        | -        | -        | -        | -        | -        | -         | 18,318   | Smith LLC        | 40   |\n",
      "| `price`           | 30,000.00 | 251.41   | 376.93   | -499.80  | 44.55    | 125.36   | 297.94   | 1,999.78  | -        | -                | -    |\n",
      "| `cost`            | 30,000.00 | 222.11   | 293.43   | 1.54     | 41.97    | 108.33   | 258.52   | 1,789.46  | -        | -                | -    |\n",
      "| `currency`        | 30,000    | -        | -        | -        | -        | -        | -        | -         | 3        | GBP              | 10,064|\n",
      "| `stock_quantity`  | 30,000.00 | 460.02   | 351.94   | -999.00  | 215.00   | 480.00   | 743.00   | 1,000.00  | -        | -                | -    |\n",
      "| `reorder_level`   | 30,000.00 | 55.15    | 26.39    | 10.00    | 32.00    | 55.00    | 78.00    | 100.00    | -        | -                | -    |\n",
      "| `weight`          | 27,085.00 | 33,252.89| 179,232.13| 0.10    | 12.89    | 25.88    | 38.57    | 999,999.99| -        | -                | -    |\n",
      "| `dimensions`      | 30,000    | -        | -        | -        | -        | -        | -        | -         | 27,138   | 71x75x85 cm      | 4    |\n",
      "| `color`           | 30,000    | -        | -        | -        | -        | -        | -        | -         | 140      | LightSlateGray   | 256  |\n",
      "| `size`            | 30,000    | -        | -        | -        | -        | -        | -        | -         | 7        | S                | 4,395|\n",
      "| `material`        | 30,000    | -        | -        | -        | -        | -        | -        | -         | 7        | Metal            | 4,411|\n",
      "| `rating`          | 30,000.00 | 5.60     | 12.80    | 1.00     | 2.00     | 3.10     | 4.10     | 100.00    | -        | -                | -    |\n",
      "| `review_count`    | 30,000.00 | 2,488.51 | 1,446.80 | 0.00     | 1,231.00 | 2,493.00 | 3,725.00 | 5,000.00  | -        | -                | -    |\n",
      "| `is_available`    | 30,000    | -        | -        | -        | -        | -        | -        | -         | 2        | True             | 29,977|\n",
      "| `is_featured`     | 30,000    | -        | -        | -        | -        | -        | -        | -         | 2        | True             | 15,012|\n",
      "| `discount_percentage` | 30,000.00 | 15.01 | 8.65    | 0.00     | 7.60     | 15.10    | 22.50    | 30.00     | -        | -                | -    |\n",
      "| `created_date`    | 30,000    | -        | -        | -        | -        | -        | -        | -         | 1,096    | 2025-06-02       | 49   |\n",
      "| `last_updated`    | 30,000    | -        | -        | -        | -        | -        | -        | -         | 1,056    | 2025-11-18       | 211  |\n",
      "\n",
      "---\n",
      "\n",
      "### **Recommendations**\n",
      "1. **Establish Data Quality Framework**\n",
      "   - Only 33% of checks passed. Consider implementing: 1) Data validation at ingestion, 2) Regular quality monitoring, 3) Data stewardship roles, 4) Quality metrics dashboards.\n",
      "   - *Priority*: High\n",
      "\n",
      "2. **Implement Null Handling Strategy**\n",
      "   - Columns `supplier`, `description`, `brand` have 5-20% null values. Consider implementing NOT NULL constraints, data validation rules, or imputation strategies based on business logic.\n",
      "   - *Priority*: Medium\n",
      "\n",
      "3. **Investigate High Variability in `weight`**\n",
      "   - Column `weight` has high variability (CV=5.39). Review for outliers, data entry errors, or consider data transformation/normalization techniques.\n",
      "   - *Priority*: Low\n",
      "\n",
      "4. **Investigate High Variability in `rating`**\n",
      "   - Column `rating` has high variability (CV=2.29). Review for outliers, data entry errors, or consider data transformation/normalization techniques.\n",
      "   - *Priority*: Low\n",
      "\n",
      "5. **Data Documentation and Profiling**\n",
      "   - Dataset has 25 columns. Consider creating data dictionaries, establishing column-level monitoring, and implementing regular statistical profiling to track data drift over time.\n",
      "   - *Priority*: Low\n",
      "\n",
      "---\n",
      "\n",
      "**Generated by**: LLM Data Quality Agent  \n",
      "**Generation Time**: 2025-11-27  \n",
      "**Report Format**: Markdown  \n",
      "\n",
      "*This report was automatically generated. Please review recommendations and take appropriate action.*\n",
      "Smart DQ check successful - proceeding with report generation...\n",
      "Extracted info:\n",
      "   Dataset: stage_sales.public.products\n",
      "   Connector: postgres\n",
      "\n",
      "Running comprehensive DQ assessment with reliable data sources...\n",
      "   Executing duplicates check...\n",
      "--- Loading data for: stage_sales.public.products using POSTGRES connector ---\n",
      "‚úì Connected to PostgreSQL: stage_sales\n",
      "Executing query: SELECT * FROM stage_sales.public.products\n",
      "\u001b[32;1m\u001b[1;3m### Comprehensive Data Quality Report for `stage_sales.public.products` (Postgres)\n",
      "\n",
      "---\n",
      "\n",
      "#### **Dataset Information**\n",
      "- **Dataset**: `stage_sales.public.products`\n",
      "- **Connector**: POSTGRES\n",
      "- **Assessment Date**: 2025-11-27\n",
      "- **Total Checks**: 3\n",
      "\n",
      "---\n",
      "\n",
      "### **Executive Summary**\n",
      "- ‚úÖ **Passed**: 1 checks\n",
      "- ‚ùå **Failed**: 2 checks\n",
      "- üö´ **Errors**: 0 checks\n",
      "\n",
      "---\n",
      "\n",
      "### **Detailed Check Results**\n",
      "\n",
      "#### ‚ùå **Duplicates**\n",
      "- **Status**: ERROR\n",
      "- **Error**: Unknown error\n",
      "\n",
      "---\n",
      "\n",
      "#### ‚úÖ **Null Values**\n",
      "- **Status**: FAIL\n",
      "- **Dataset Size**: 30,000 rows √ó 25 columns\n",
      "- **Columns with Missing Data**: 4 out of 25 columns\n",
      "- **Missing Data Coverage**: 16.0% of columns affected\n",
      "\n",
      "**Detailed Null Analysis**:\n",
      "- `supplier`: 5,400 nulls (18.0%)\n",
      "- `description`: 4,500 nulls (15.0%)\n",
      "- `brand`: 3,600 nulls (12.0%)\n",
      "- `weight`: 2,915 nulls (9.7%)\n",
      "\n",
      "---\n",
      "\n",
      "#### ‚úÖ **Descriptive Stats**\n",
      "- **Status**: PASS (Statistics Generated)\n",
      "- **Columns Analyzed**: 25 columns\n",
      "\n",
      "**üìä Complete Statistical Summary**:\n",
      "\n",
      "| Column            | Count     | Mean     | Std      | Min      | 25%      | 50%      | 75%      | Max       | Unique   | Top              | Freq |\n",
      "|-------------------|-----------|----------|----------|----------|----------|----------|----------|-----------|----------|------------------|------|\n",
      "| `product_id`      | 30,000.00 | -        | -        | -        | -        | -        | -        | -         | 27,600.00 | 24,390.00        | 4    |\n",
      "| `sku`             | 30,000    | -        | -        | -        | -        | -        | -        | -         | 27,169   | SKU-465741       | 5    |\n",
      "| `product_name`    | 30,000    | -        | -        | -        | -        | -        | -        | -         | 27,212   | Automated multi  | 4    |\n",
      "| `description`     | 25,500    | -        | -        | -        | -        | -        | -        | -         | 23,748   | Mrs blood yard   | 4    |\n",
      "| `category`        | 30,000    | -        | -        | -        | -        | -        | -        | -         | 10       | Office Supplies  | 3,096|\n",
      "| `subcategory`     | 30,000    | -        | -        | -        | -        | -        | -        | -         | 971      | Media            | 52   |\n",
      "| `brand`           | 26,400    | -        | -        | -        | -        | -        | -        | -         | 19,489   | Smith LLC        | 39   |\n",
      "| `supplier`        | 24,600    | -        | -        | -        | -        | -        | -        | -         | 18,318   | Smith LLC        | 40   |\n",
      "| `price`           | 30,000.00 | 251.41   | 376.93   | -499.80  | 44.55    | 125.36   | 297.94   | 1,999.78  | -        | -                | -    |\n",
      "| `cost`            | 30,000.00 | 222.11   | 293.43   | 1.54     | 41.97    | 108.33   | 258.52   | 1,789.46  | -        | -                | -    |\n",
      "| `currency`        | 30,000    | -        | -        | -        | -        | -        | -        | -         | 3        | GBP              | 10,064|\n",
      "| `stock_quantity`  | 30,000.00 | 460.02   | 351.94   | -999.00  | 215.00   | 480.00   | 743.00   | 1,000.00  | -        | -                | -    |\n",
      "| `reorder_level`   | 30,000.00 | 55.15    | 26.39    | 10.00    | 32.00    | 55.00    | 78.00    | 100.00    | -        | -                | -    |\n",
      "| `weight`          | 27,085.00 | 33,252.89| 179,232.13| 0.10    | 12.89    | 25.88    | 38.57    | 999,999.99| -        | -                | -    |\n",
      "| `dimensions`      | 30,000    | -        | -        | -        | -        | -        | -        | -         | 27,138   | 71x75x85 cm      | 4    |\n",
      "| `color`           | 30,000    | -        | -        | -        | -        | -        | -        | -         | 140      | LightSlateGray   | 256  |\n",
      "| `size`            | 30,000    | -        | -        | -        | -        | -        | -        | -         | 7        | S                | 4,395|\n",
      "| `material`        | 30,000    | -        | -        | -        | -        | -        | -        | -         | 7        | Metal            | 4,411|\n",
      "| `rating`          | 30,000.00 | 5.60     | 12.80    | 1.00     | 2.00     | 3.10     | 4.10     | 100.00    | -        | -                | -    |\n",
      "| `review_count`    | 30,000.00 | 2,488.51 | 1,446.80 | 0.00     | 1,231.00 | 2,493.00 | 3,725.00 | 5,000.00  | -        | -                | -    |\n",
      "| `is_available`    | 30,000    | -        | -        | -        | -        | -        | -        | -         | 2        | True             | 29,977|\n",
      "| `is_featured`     | 30,000    | -        | -        | -        | -        | -        | -        | -         | 2        | True             | 15,012|\n",
      "| `discount_percentage` | 30,000.00 | 15.01 | 8.65    | 0.00     | 7.60     | 15.10    | 22.50    | 30.00     | -        | -                | -    |\n",
      "| `created_date`    | 30,000    | -        | -        | -        | -        | -        | -        | -         | 1,096    | 2025-06-02       | 49   |\n",
      "| `last_updated`    | 30,000    | -        | -        | -        | -        | -        | -        | -         | 1,056    | 2025-11-18       | 211  |\n",
      "\n",
      "---\n",
      "\n",
      "### **Recommendations**\n",
      "1. **Establish Data Quality Framework**\n",
      "   - Only 33% of checks passed. Consider implementing: 1) Data validation at ingestion, 2) Regular quality monitoring, 3) Data stewardship roles, 4) Quality metrics dashboards.\n",
      "   - *Priority*: High\n",
      "\n",
      "2. **Implement Null Handling Strategy**\n",
      "   - Columns `supplier`, `description`, `brand` have 5-20% null values. Consider implementing NOT NULL constraints, data validation rules, or imputation strategies based on business logic.\n",
      "   - *Priority*: Medium\n",
      "\n",
      "3. **Investigate High Variability in `weight`**\n",
      "   - Column `weight` has high variability (CV=5.39). Review for outliers, data entry errors, or consider data transformation/normalization techniques.\n",
      "   - *Priority*: Low\n",
      "\n",
      "4. **Investigate High Variability in `rating`**\n",
      "   - Column `rating` has high variability (CV=2.29). Review for outliers, data entry errors, or consider data transformation/normalization techniques.\n",
      "   - *Priority*: Low\n",
      "\n",
      "5. **Data Documentation and Profiling**\n",
      "   - Dataset has 25 columns. Consider creating data dictionaries, establishing column-level monitoring, and implementing regular statistical profiling to track data drift over time.\n",
      "   - *Priority*: Low\n",
      "\n",
      "---\n",
      "\n",
      "**Generated by**: LLM Data Quality Agent  \n",
      "**Generation Time**: 2025-11-27  \n",
      "**Report Format**: Markdown  \n",
      "\n",
      "*This report was automatically generated. Please review recommendations and take appropriate action.*\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "======================================================================\n",
      "RESULT\n",
      "======================================================================\n",
      "\n",
      "Report output: ### Comprehensive Data Quality Report for `stage_sales.public.products` (Postgres)\n",
      "\n",
      "---\n",
      "\n",
      "#### **Dataset Information**\n",
      "- **Dataset**: `stage_sales.public.products`\n",
      "- **Connector**: POSTGRES\n",
      "- **Assessment Date**: 2025-11-27\n",
      "- **Total Checks**: 3\n",
      "\n",
      "---\n",
      "\n",
      "### **Executive Summary**\n",
      "- ‚úÖ **Passed**: 1 checks\n",
      "- ‚ùå **Failed**: 2 checks\n",
      "- üö´ **Errors**: 0 checks\n",
      "\n",
      "---\n",
      "\n",
      "### **Detailed Check Results**\n",
      "\n",
      "#### ‚ùå **Duplicates**\n",
      "- **Status**: ERROR\n",
      "- **Error**: Unknown error\n",
      "\n",
      "---\n",
      "\n",
      "#### ‚úÖ **Null Values**\n",
      "- **Status**: FAIL\n",
      "- **Dataset Size**: 30,000 rows √ó 25 columns\n",
      "- **Columns with Missing Data**: 4 out of 25 columns\n",
      "- **Missing Data Coverage**: 16.0% of columns affected\n",
      "\n",
      "**Detailed Null Analysis**:\n",
      "- `supplier`: 5,400 nulls (18.0%)\n",
      "- `description`: 4,500 nulls (15.0%)\n",
      "- `brand`: 3,600 nulls (12.0%)\n",
      "- `weight`: 2,915 nulls (9.7%)\n",
      "\n",
      "---\n",
      "\n",
      "#### ‚úÖ **Descriptive Stats**\n",
      "- **Status**: PASS (Statistics Generated)\n",
      "- **Columns Analyzed**: 25 columns\n",
      "\n",
      "**üìä Complete Statistical Summary**:\n",
      "\n",
      "| Column            | Count     | Mean     | Std      | Min      | 25%      | 50%      | 75%      | Max       | Unique   | Top              | Freq |\n",
      "|-------------------|-----------|----------|----------|----------|----------|----------|----------|-----------|----------|------------------|------|\n",
      "| `product_id`      | 30,000.00 | -        | -        | -        | -        | -        | -        | -         | 27,600.00 | 24,390.00        | 4    |\n",
      "| `sku`             | 30,000    | -        | -        | -        | -        | -        | -        | -         | 27,169   | SKU-465741       | 5    |\n",
      "| `product_name`    | 30,000    | -        | -        | -        | -        | -        | -        | -         | 27,212   | Automated multi  | 4    |\n",
      "| `description`     | 25,500    | -        | -        | -        | -        | -        | -        | -         | 23,748   | Mrs blood yard   | 4    |\n",
      "| `category`        | 30,000    | -        | -        | -        | -        | -        | -        | -         | 10       | Office Supplies  | 3,096|\n",
      "| `subcategory`     | 30,000    | -        | -        | -        | -        | -        | -        | -         | 971      | Media            | 52   |\n",
      "| `brand`           | 26,400    | -        | -        | -        | -        | -        | -        | -         | 19,489   | Smith LLC        | 39   |\n",
      "| `supplier`        | 24,600    | -        | -        | -        | -        | -        | -        | -         | 18,318   | Smith LLC        | 40   |\n",
      "| `price`           | 30,000.00 | 251.41   | 376.93   | -499.80  | 44.55    | 125.36   | 297.94   | 1,999.78  | -        | -                | -    |\n",
      "| `cost`            | 30,000.00 | 222.11   | 293.43   | 1.54     | 41.97    | 108.33   | 258.52   | 1,789.46  | -        | -                | -    |\n",
      "| `currency`        | 30,000    | -        | -        | -        | -        | -        | -        | -         | 3        | GBP              | 10,064|\n",
      "| `stock_quantity`  | 30,000.00 | 460.02   | 351.94   | -999.00  | 215.00   | 480.00   | 743.00   | 1,000.00  | -        | -                | -    |\n",
      "| `reorder_level`   | 30,000.00 | 55.15    | 26.39    | 10.00    | 32.00    | 55.00    | 78.00    | 100.00    | -        | -                | -    |\n",
      "| `weight`          | 27,085.00 | 33,252.89| 179,232.13| 0.10    | 12.89    | 25.88    | 38.57    | 999,999.99| -        | -                | -    |\n",
      "| `dimensions`      | 30,000    | -        | -        | -        | -        | -        | -        | -         | 27,138   | 71x75x85 cm      | 4    |\n",
      "| `color`           | 30,000    | -        | -        | -        | -        | -        | -        | -         | 140      | LightSlateGray   | 256  |\n",
      "| `size`            | 30,000    | -        | -        | -        | -        | -        | -        | -         | 7        | S                | 4,395|\n",
      "| `material`        | 30,000    | -        | -        | -        | -        | -        | -        | -         | 7        | Metal            | 4,411|\n",
      "| `rating`          | 30,000.00 | 5.60     | 12.80    | 1.00     | 2.00     | 3.10     | 4.10     | 100.00    | -        | -                | -    |\n",
      "| `review_count`    | 30,000.00 | 2,488.51 | 1,446.80 | 0.00     | 1,231.00 | 2,493.00 | 3,725.00 | 5,000.00  | -        | -                | -    |\n",
      "| `is_available`    | 30,000    | -        | -        | -        | -        | -        | -        | -         | 2        | True             | 29,977|\n",
      "| `is_featured`     | 30,000    | -        | -        | -        | -        | -        | -        | -         | 2        | True             | 15,012|\n",
      "| `discount_percentage` | 30,000.00 | 15.01 | 8.65    | 0.00     | 7.60     | 15.10    | 22.50    | 30.00     | -        | -                | -    |\n",
      "| `created_date`    | 30,000    | -        | -        | -        | -        | -        | -        | -         | 1,096    | 2025-06-02       | 49   |\n",
      "| `last_updated`    | 30,000    | -        | -        | -        | -        | -        | -        | -         | 1,056    | 2025-11-18       | 211  |\n",
      "\n",
      "---\n",
      "\n",
      "### **Recommendations**\n",
      "1. **Establish Data Quality Framework**\n",
      "   - Only 33% of checks passed. Consider implementing: 1) Data validation at ingestion, 2) Regular quality monitoring, 3) Data stewardship roles, 4) Quality metrics dashboards.\n",
      "   - *Priority*: High\n",
      "\n",
      "2. **Implement Null Handling Strategy**\n",
      "   - Columns `supplier`, `description`, `brand` have 5-20% null values. Consider implementing NOT NULL constraints, data validation rules, or imputation strategies based on business logic.\n",
      "   - *Priority*: Medium\n",
      "\n",
      "3. **Investigate High Variability in `weight`**\n",
      "   - Column `weight` has high variability (CV=5.39). Review for outliers, data entry errors, or consider data transformation/normalization techniques.\n",
      "   - *Priority*: Low\n",
      "\n",
      "4. **Investigate High Variability in `rating`**\n",
      "   - Column `rating` has high variability (CV=2.29). Review for outliers, data entry errors, or consider data transformation/normalization techniques.\n",
      "   - *Priority*: Low\n",
      "\n",
      "5. **Data Documentation and Profiling**\n",
      "   - Dataset has 25 columns. Consider creating data dictionaries, establishing column-level monitoring, and implementing regular statistical profiling to track data drift over time.\n",
      "   - *Priority*: Low\n",
      "\n",
      "---\n",
      "\n",
      "**Generated by**: LLM Data Quality Agent  \n",
      "**Generation Time**: 2025-11-27  \n",
      "**Report Format**: Markdown  \n",
      "\n",
      "*This report was automatically generated. Please review recommendations and take appropriate action.*\n",
      "Smart DQ check successful - proceeding with report generation...\n",
      "Extracted info:\n",
      "   Dataset: stage_sales.public.products\n",
      "   Connector: postgres\n",
      "\n",
      "Running comprehensive DQ assessment with reliable data sources...\n",
      "   Executing duplicates check...\n",
      "--- Loading data for: stage_sales.public.products using POSTGRES connector ---\n",
      "‚úì Connected to PostgreSQL: stage_sales\n",
      "Executing query: SELECT * FROM stage_sales.public.products\n",
      "‚úì Loaded 30000 rows from PostgreSQL\n",
      "‚úì Disconnected from PostgreSQL\n",
      "   Executing null_values check...\n",
      "--- Loading data for: stage_sales.public.products using POSTGRES connector ---\n",
      "‚úì Loaded 30000 rows from PostgreSQL\n",
      "‚úì Disconnected from PostgreSQL\n",
      "   Executing null_values check...\n",
      "--- Loading data for: stage_sales.public.products using POSTGRES connector ---\n",
      "‚úì Connected to PostgreSQL: stage_sales\n",
      "Executing query: SELECT * FROM stage_sales.public.products\n",
      "‚úì Connected to PostgreSQL: stage_sales\n",
      "Executing query: SELECT * FROM stage_sales.public.products\n",
      "‚úì Loaded 30000 rows from PostgreSQL\n",
      "‚úì Disconnected from PostgreSQL\n",
      "   Executing descriptive_stats check...\n",
      "--- Loading data for: stage_sales.public.products using POSTGRES connector ---\n",
      "‚úì Loaded 30000 rows from PostgreSQL\n",
      "‚úì Disconnected from PostgreSQL\n",
      "   Executing descriptive_stats check...\n",
      "--- Loading data for: stage_sales.public.products using POSTGRES connector ---\n",
      "‚úì Connected to PostgreSQL: stage_sales\n",
      "Executing query: SELECT * FROM stage_sales.public.products\n",
      "‚úì Connected to PostgreSQL: stage_sales\n",
      "Executing query: SELECT * FROM stage_sales.public.products\n",
      "‚úì Loaded 30000 rows from PostgreSQL\n",
      "‚úì Disconnected from PostgreSQL\n",
      "‚úì Converted 'product_id' to categorical for descriptive statistics\n",
      "    Assessment completed using direct DQ check execution!\n",
      "    Data consistency guaranteed - no parsing errors!\n",
      "\n",
      "Generating reports using standardized templates...\n",
      "   MARKDOWN: ../reports/comprehensive_dq_report_stage_sales_products_20251127_135036.md\n",
      "   HTML: ../reports/comprehensive_dq_report_stage_sales_products_20251127_135036.html\n",
      "   JSON: ../reports/comprehensive_dq_report_stage_sales_products_20251127_135036.json\n",
      "2, Report processing complete.\n",
      "\n",
      " Running DQ check for query: Check prod customers table for missing values\n",
      "\n",
      "======================================================================\n",
      "SMART DATA QUALITY CHECK\n",
      "======================================================================\n",
      "User Query: Check prod customers table for missing values\n",
      "\n",
      "Step 1: Discovering relevant tables...\n",
      "----------------------------------------------------------------------\n",
      "‚úì Loaded 30000 rows from PostgreSQL\n",
      "‚úì Disconnected from PostgreSQL\n",
      "‚úì Converted 'product_id' to categorical for descriptive statistics\n",
      "    Assessment completed using direct DQ check execution!\n",
      "    Data consistency guaranteed - no parsing errors!\n",
      "\n",
      "Generating reports using standardized templates...\n",
      "   MARKDOWN: ../reports/comprehensive_dq_report_stage_sales_products_20251127_135036.md\n",
      "   HTML: ../reports/comprehensive_dq_report_stage_sales_products_20251127_135036.html\n",
      "   JSON: ../reports/comprehensive_dq_report_stage_sales_products_20251127_135036.json\n",
      "2, Report processing complete.\n",
      "\n",
      " Running DQ check for query: Check prod customers table for missing values\n",
      "\n",
      "======================================================================\n",
      "SMART DATA QUALITY CHECK\n",
      "======================================================================\n",
      "User Query: Check prod customers table for missing values\n",
      "\n",
      "Step 1: Discovering relevant tables...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Number of requested results 20 is greater than number of elements in index 9, updating n_results = 9\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Number of requested results 20 is greater than number of elements in index 9, updating n_results = 9\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 3 relevant table(s) (‚â•5% relevance):\n",
      "\n",
      "  1. [SNOWFLAKE] PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "     Relevance: 34.92% ‚úì\n",
      "\n",
      "  2. [SNOWFLAKE] PROD_SALES.DATA_MART_MANUFACTURING.PRODUCTS\n",
      "     Relevance: 12.31% ‚úì\n",
      "\n",
      "  3. [SNOWFLAKE] PROD_SALES.DATA_MART_MARKETING.CALL_CENTER\n",
      "     Relevance: 5.50% ‚úì\n",
      "\n",
      "Step 2: Building context for agent...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Step 3: Running agent with discovered tables...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `check_dataset_null_values` with `{'dataset_id': 'PROD_SALES.DATA_MART_MARKETING.CUSTOMERS', 'connector_type': 'snowflake'}`\n",
      "\n",
      "\n",
      "\u001b[0m--- Loading data for: PROD_SALES.DATA_MART_MARKETING.CUSTOMERS using SNOWFLAKE connector ---\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `check_dataset_null_values` with `{'dataset_id': 'PROD_SALES.DATA_MART_MARKETING.CUSTOMERS', 'connector_type': 'snowflake'}`\n",
      "\n",
      "\n",
      "\u001b[0m--- Loading data for: PROD_SALES.DATA_MART_MARKETING.CUSTOMERS using SNOWFLAKE connector ---\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "‚úì Loaded 37811 rows from Snowflake\n",
      "‚úì Disconnected from Snowflake\n",
      "‚úì Loaded 37811 rows from Snowflake\n",
      "‚úì Disconnected from Snowflake\n",
      "\u001b[33;1m\u001b[1;3m{'dataset_id': 'PROD_SALES.DATA_MART_MARKETING.CUSTOMERS', 'total_rows': 37811, 'total_columns': 22, 'columns_with_nulls': 3, 'null_analysis': [{'column_name': 'COMPANY', 'null_count': 6927, 'null_percentage': 18.32}, {'column_name': 'PHONE', 'null_count': 5794, 'null_percentage': 15.32}, {'column_name': 'ADDRESS', 'null_count': 3130, 'null_percentage': 8.28}], 'status': 'success'}\u001b[0m\u001b[33;1m\u001b[1;3m{'dataset_id': 'PROD_SALES.DATA_MART_MARKETING.CUSTOMERS', 'total_rows': 37811, 'total_columns': 22, 'columns_with_nulls': 3, 'null_analysis': [{'column_name': 'COMPANY', 'null_count': 6927, 'null_percentage': 18.32}, {'column_name': 'PHONE', 'null_count': 5794, 'null_percentage': 15.32}, {'column_name': 'ADDRESS', 'null_count': 3130, 'null_percentage': 8.28}], 'status': 'success'}\u001b[0m\u001b[32;1m\u001b[1;3m### Null Values Analysis for Table: `PROD_SALES.DATA_MART_MARKETING.CUSTOMERS`\n",
      "\n",
      "**Dataset Overview**:\n",
      "- **Total Rows**: 37,811\n",
      "- **Total Columns**: 22\n",
      "- **Columns with Missing Data**: 3\n",
      "\n",
      "**Missing Data Details**:\n",
      "- `COMPANY`: 6,927 nulls (18.32%)\n",
      "- `PHONE`: 5,794 nulls (15.32%)\n",
      "- `ADDRESS`: 3,130 nulls (8.28%)\n",
      "\n",
      "This analysis highlights the columns with significant missing data percentages. Let me know if you need further checks or a comprehensive report!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "======================================================================\n",
      "RESULT\n",
      "======================================================================\n",
      "\n",
      "Report output: ### Null Values Analysis for Table: `PROD_SALES.DATA_MART_MARKETING.CUSTOMERS`\n",
      "\n",
      "**Dataset Overview**:\n",
      "- **Total Rows**: 37,811\n",
      "- **Total Columns**: 22\n",
      "- **Columns with Missing Data**: 3\n",
      "\n",
      "**Missing Data Details**:\n",
      "- `COMPANY`: 6,927 nulls (18.32%)\n",
      "- `PHONE`: 5,794 nulls (15.32%)\n",
      "- `ADDRESS`: 3,130 nulls (8.28%)\n",
      "\n",
      "This analysis highlights the columns with significant missing data percentages. Let me know if you need further checks or a comprehensive report!\n",
      "Smart DQ check successful - proceeding with report generation...\n",
      "Extracted info:\n",
      "   Dataset: PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "   Connector: snowflake\n",
      "\n",
      "Running comprehensive DQ assessment with reliable data sources...\n",
      "   Executing duplicates check...\n",
      "--- Loading data for: PROD_SALES.DATA_MART_MARKETING.CUSTOMERS using SNOWFLAKE connector ---\n",
      "\u001b[32;1m\u001b[1;3m### Null Values Analysis for Table: `PROD_SALES.DATA_MART_MARKETING.CUSTOMERS`\n",
      "\n",
      "**Dataset Overview**:\n",
      "- **Total Rows**: 37,811\n",
      "- **Total Columns**: 22\n",
      "- **Columns with Missing Data**: 3\n",
      "\n",
      "**Missing Data Details**:\n",
      "- `COMPANY`: 6,927 nulls (18.32%)\n",
      "- `PHONE`: 5,794 nulls (15.32%)\n",
      "- `ADDRESS`: 3,130 nulls (8.28%)\n",
      "\n",
      "This analysis highlights the columns with significant missing data percentages. Let me know if you need further checks or a comprehensive report!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "======================================================================\n",
      "RESULT\n",
      "======================================================================\n",
      "\n",
      "Report output: ### Null Values Analysis for Table: `PROD_SALES.DATA_MART_MARKETING.CUSTOMERS`\n",
      "\n",
      "**Dataset Overview**:\n",
      "- **Total Rows**: 37,811\n",
      "- **Total Columns**: 22\n",
      "- **Columns with Missing Data**: 3\n",
      "\n",
      "**Missing Data Details**:\n",
      "- `COMPANY`: 6,927 nulls (18.32%)\n",
      "- `PHONE`: 5,794 nulls (15.32%)\n",
      "- `ADDRESS`: 3,130 nulls (8.28%)\n",
      "\n",
      "This analysis highlights the columns with significant missing data percentages. Let me know if you need further checks or a comprehensive report!\n",
      "Smart DQ check successful - proceeding with report generation...\n",
      "Extracted info:\n",
      "   Dataset: PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "   Connector: snowflake\n",
      "\n",
      "Running comprehensive DQ assessment with reliable data sources...\n",
      "   Executing duplicates check...\n",
      "--- Loading data for: PROD_SALES.DATA_MART_MARKETING.CUSTOMERS using SNOWFLAKE connector ---\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "‚úì Loaded 37811 rows from Snowflake\n",
      "‚úì Disconnected from Snowflake\n",
      "‚úì Loaded 37811 rows from Snowflake\n",
      "‚úì Disconnected from Snowflake\n",
      "   Executing null_values check...\n",
      "--- Loading data for: PROD_SALES.DATA_MART_MARKETING.CUSTOMERS using SNOWFLAKE connector ---\n",
      "   Executing null_values check...\n",
      "--- Loading data for: PROD_SALES.DATA_MART_MARKETING.CUSTOMERS using SNOWFLAKE connector ---\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "‚úì Loaded 37811 rows from Snowflake\n",
      "‚úì Disconnected from Snowflake\n",
      "‚úì Loaded 37811 rows from Snowflake\n",
      "‚úì Disconnected from Snowflake\n",
      "   Executing descriptive_stats check...\n",
      "--- Loading data for: PROD_SALES.DATA_MART_MARKETING.CUSTOMERS using SNOWFLAKE connector ---\n",
      "   Executing descriptive_stats check...\n",
      "--- Loading data for: PROD_SALES.DATA_MART_MARKETING.CUSTOMERS using SNOWFLAKE connector ---\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "‚úì Loaded 37811 rows from Snowflake\n",
      "‚úì Disconnected from Snowflake\n",
      "‚úì Converted 'CUSTOMER_ID' to categorical for descriptive statistics\n",
      "‚úì Loaded 37811 rows from Snowflake\n",
      "‚úì Disconnected from Snowflake\n",
      "‚úì Converted 'CUSTOMER_ID' to categorical for descriptive statistics\n",
      "    Assessment completed using direct DQ check execution!\n",
      "    Data consistency guaranteed - no parsing errors!\n",
      "\n",
      "Generating reports using standardized templates...\n",
      "   MARKDOWN: ../reports/comprehensive_dq_report_prod_sales_customers_20251127_135059.md\n",
      "   HTML: ../reports/comprehensive_dq_report_prod_sales_customers_20251127_135059.html\n",
      "   JSON: ../reports/comprehensive_dq_report_prod_sales_customers_20251127_135059.json\n",
      "3, Report processing complete.\n",
      "\n",
      " Running DQ check for query: Find duplicates in production invoice table snowflake\n",
      "\n",
      "======================================================================\n",
      "SMART DATA QUALITY CHECK\n",
      "======================================================================\n",
      "User Query: Find duplicates in production invoice table snowflake\n",
      "\n",
      "Step 1: Discovering relevant tables...\n",
      "----------------------------------------------------------------------\n",
      "    Assessment completed using direct DQ check execution!\n",
      "    Data consistency guaranteed - no parsing errors!\n",
      "\n",
      "Generating reports using standardized templates...\n",
      "   MARKDOWN: ../reports/comprehensive_dq_report_prod_sales_customers_20251127_135059.md\n",
      "   HTML: ../reports/comprehensive_dq_report_prod_sales_customers_20251127_135059.html\n",
      "   JSON: ../reports/comprehensive_dq_report_prod_sales_customers_20251127_135059.json\n",
      "3, Report processing complete.\n",
      "\n",
      " Running DQ check for query: Find duplicates in production invoice table snowflake\n",
      "\n",
      "======================================================================\n",
      "SMART DATA QUALITY CHECK\n",
      "======================================================================\n",
      "User Query: Find duplicates in production invoice table snowflake\n",
      "\n",
      "Step 1: Discovering relevant tables...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Number of requested results 20 is greater than number of elements in index 9, updating n_results = 9\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Number of requested results 20 is greater than number of elements in index 9, updating n_results = 9\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 3 relevant table(s) (‚â•5% relevance):\n",
      "\n",
      "  1. [SNOWFLAKE] PROD_SALES.DATA_MART_FINANCE.INVOICES\n",
      "     Relevance: 56.88% ‚úì\n",
      "\n",
      "  2. [SNOWFLAKE] PROD_SALES.DATA_MART_MARKETING.CALL_CENTER\n",
      "     Relevance: 22.37% ‚úì\n",
      "\n",
      "  3. [SNOWFLAKE] PROD_SALES.DATA_MART_MARKETING.SALES\n",
      "     Relevance: 13.12% ‚úì\n",
      "\n",
      "Step 2: Building context for agent...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Step 3: Running agent with discovered tables...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `check_dataset_duplicates` with `{'dataset_id': 'PROD_SALES.DATA_MART_FINANCE.INVOICES', 'connector_type': 'snowflake'}`\n",
      "\n",
      "\n",
      "\u001b[0m--- Loading data for: PROD_SALES.DATA_MART_FINANCE.INVOICES using SNOWFLAKE connector ---\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `check_dataset_duplicates` with `{'dataset_id': 'PROD_SALES.DATA_MART_FINANCE.INVOICES', 'connector_type': 'snowflake'}`\n",
      "\n",
      "\n",
      "\u001b[0m--- Loading data for: PROD_SALES.DATA_MART_FINANCE.INVOICES using SNOWFLAKE connector ---\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_FINANCE.INVOICES\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_FINANCE.INVOICES\n",
      "‚úì Loaded 91685 rows from Snowflake\n",
      "‚úì Disconnected from Snowflake\n",
      "‚úì Loaded 91685 rows from Snowflake\n",
      "‚úì Disconnected from Snowflake\n",
      "\u001b[36;1m\u001b[1;3m{'dataset_id': 'PROD_SALES.DATA_MART_FINANCE.INVOICES', 'total_rows': 91685, 'duplicate_qty': 0, 'status': 'success'}\u001b[0m\u001b[36;1m\u001b[1;3m{'dataset_id': 'PROD_SALES.DATA_MART_FINANCE.INVOICES', 'total_rows': 91685, 'duplicate_qty': 0, 'status': 'success'}\u001b[0m\u001b[32;1m\u001b[1;3m### Duplicate Records Analysis for Table: `PROD_SALES.DATA_MART_FINANCE.INVOICES`\n",
      "\n",
      "- **Total Rows**: 91,685\n",
      "- **Duplicate Records**: 0\n",
      "\n",
      "The analysis indicates that there are no duplicate records in the `PROD_SALES.DATA_MART_FINANCE.INVOICES` table. The data appears to be clean with respect to duplicate entries.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "======================================================================\n",
      "RESULT\n",
      "======================================================================\n",
      "\n",
      "Report output: ### Duplicate Records Analysis for Table: `PROD_SALES.DATA_MART_FINANCE.INVOICES`\n",
      "\n",
      "- **Total Rows**: 91,685\n",
      "- **Duplicate Records**: 0\n",
      "\n",
      "The analysis indicates that there are no duplicate records in the `PROD_SALES.DATA_MART_FINANCE.INVOICES` table. The data appears to be clean with respect to duplicate entries.\n",
      "Smart DQ check successful - proceeding with report generation...\n",
      "Extracted info:\n",
      "   Dataset: PROD_SALES.DATA_MART_FINANCE.INVOICES\n",
      "   Connector: snowflake\n",
      "\n",
      "Running comprehensive DQ assessment with reliable data sources...\n",
      "   Executing duplicates check...\n",
      "--- Loading data for: PROD_SALES.DATA_MART_FINANCE.INVOICES using SNOWFLAKE connector ---\n",
      "\u001b[32;1m\u001b[1;3m### Duplicate Records Analysis for Table: `PROD_SALES.DATA_MART_FINANCE.INVOICES`\n",
      "\n",
      "- **Total Rows**: 91,685\n",
      "- **Duplicate Records**: 0\n",
      "\n",
      "The analysis indicates that there are no duplicate records in the `PROD_SALES.DATA_MART_FINANCE.INVOICES` table. The data appears to be clean with respect to duplicate entries.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "======================================================================\n",
      "RESULT\n",
      "======================================================================\n",
      "\n",
      "Report output: ### Duplicate Records Analysis for Table: `PROD_SALES.DATA_MART_FINANCE.INVOICES`\n",
      "\n",
      "- **Total Rows**: 91,685\n",
      "- **Duplicate Records**: 0\n",
      "\n",
      "The analysis indicates that there are no duplicate records in the `PROD_SALES.DATA_MART_FINANCE.INVOICES` table. The data appears to be clean with respect to duplicate entries.\n",
      "Smart DQ check successful - proceeding with report generation...\n",
      "Extracted info:\n",
      "   Dataset: PROD_SALES.DATA_MART_FINANCE.INVOICES\n",
      "   Connector: snowflake\n",
      "\n",
      "Running comprehensive DQ assessment with reliable data sources...\n",
      "   Executing duplicates check...\n",
      "--- Loading data for: PROD_SALES.DATA_MART_FINANCE.INVOICES using SNOWFLAKE connector ---\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_FINANCE.INVOICES\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_FINANCE.INVOICES\n",
      "‚úì Loaded 91685 rows from Snowflake\n",
      "‚úì Disconnected from Snowflake\n",
      "‚úì Loaded 91685 rows from Snowflake\n",
      "‚úì Disconnected from Snowflake\n",
      "   Executing null_values check...\n",
      "--- Loading data for: PROD_SALES.DATA_MART_FINANCE.INVOICES using SNOWFLAKE connector ---\n",
      "   Executing null_values check...\n",
      "--- Loading data for: PROD_SALES.DATA_MART_FINANCE.INVOICES using SNOWFLAKE connector ---\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_FINANCE.INVOICES\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_FINANCE.INVOICES\n",
      "‚úì Loaded 91685 rows from Snowflake\n",
      "‚úì Disconnected from Snowflake\n",
      "‚úì Loaded 91685 rows from Snowflake\n",
      "‚úì Disconnected from Snowflake\n",
      "   Executing descriptive_stats check...\n",
      "--- Loading data for: PROD_SALES.DATA_MART_FINANCE.INVOICES using SNOWFLAKE connector ---\n",
      "   Executing descriptive_stats check...\n",
      "--- Loading data for: PROD_SALES.DATA_MART_FINANCE.INVOICES using SNOWFLAKE connector ---\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_FINANCE.INVOICES\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_FINANCE.INVOICES\n",
      "‚úì Loaded 91685 rows from Snowflake\n",
      "‚úì Disconnected from Snowflake\n",
      "‚úì Converted 'INVOICE_ID' to categorical for descriptive statistics\n",
      "‚úì Converted 'CUSTOMER_ID' to categorical for descriptive statistics\n",
      "‚úì Converted 'PRODUCT_ID' to categorical for descriptive statistics\n",
      "‚úì Loaded 91685 rows from Snowflake\n",
      "‚úì Disconnected from Snowflake\n",
      "‚úì Converted 'INVOICE_ID' to categorical for descriptive statistics\n",
      "‚úì Converted 'CUSTOMER_ID' to categorical for descriptive statistics\n",
      "‚úì Converted 'PRODUCT_ID' to categorical for descriptive statistics\n",
      "    Assessment completed using direct DQ check execution!\n",
      "    Data consistency guaranteed - no parsing errors!\n",
      "\n",
      "Generating reports using standardized templates...\n",
      "   MARKDOWN: ../reports/comprehensive_dq_report_prod_sales_invoices_20251127_135141.md\n",
      "   HTML: ../reports/comprehensive_dq_report_prod_sales_invoices_20251127_135141.html\n",
      "   JSON: ../reports/comprehensive_dq_report_prod_sales_invoices_20251127_135141.json\n",
      "4, Report processing complete.\n",
      "    Assessment completed using direct DQ check execution!\n",
      "    Data consistency guaranteed - no parsing errors!\n",
      "\n",
      "Generating reports using standardized templates...\n",
      "   MARKDOWN: ../reports/comprehensive_dq_report_prod_sales_invoices_20251127_135141.md\n",
      "   HTML: ../reports/comprehensive_dq_report_prod_sales_invoices_20251127_135141.html\n",
      "   JSON: ../reports/comprehensive_dq_report_prod_sales_invoices_20251127_135141.json\n",
      "4, Report processing complete.\n"
     ]
    }
   ],
   "source": [
    "# Loop example queries\n",
    "\n",
    "queries = [\n",
    "\"Analyze staging analytics data quality\", # Missing table to show error handling\n",
    "\"Create comprehensive report of UNKNOWN table data quality for staging database\", # Nonsense table name to test error handling\n",
    "\"Generate comprehensive DQ report for staging sales table in postgres\",\n",
    "\"Check prod customers table for missing values\",\n",
    "\"Find duplicates in production invoice table snowflake\"\n",
    "]\n",
    "\n",
    "for _, query in enumerate(queries):\n",
    "    print(f\"\\n Running DQ check for query: {query}\")\n",
    "    report = run_smart_dq_check(query)\n",
    "    print(f\"Report output: {report.get('output', 'No output found')}\")\n",
    "    processor = SmartDQReportProcessor(reports_dir=\"../reports\")\n",
    "    processor.process_comprehensive_report(report)\n",
    "    print(f\"{_}, Report processing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aecc13",
   "metadata": {},
   "source": [
    "User Input base query and report creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c65981e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using query: Generate comprehensive DQ report for prod customers table\n",
      "\n",
      "======================================================================\n",
      "SMART DATA QUALITY CHECK\n",
      "======================================================================\n",
      "User Query: Generate comprehensive DQ report for prod customers table\n",
      "\n",
      "Step 1: Discovering relevant tables...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Number of requested results 20 is greater than number of elements in index 9, updating n_results = 9\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Number of requested results 20 is greater than number of elements in index 9, updating n_results = 9\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 3 relevant table(s) (‚â•5% relevance):\n",
      "\n",
      "  1. [SNOWFLAKE] PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "     Relevance: 37.23% ‚úì\n",
      "\n",
      "  2. [SNOWFLAKE] PROD_SALES.DATA_MART_MANUFACTURING.PRODUCTS\n",
      "     Relevance: 36.49% ‚úì\n",
      "\n",
      "  3. [SNOWFLAKE] PROD_SALES.DATA_MART_MARKETING.SALES\n",
      "     Relevance: 23.34% ‚úì\n",
      "\n",
      "Step 2: Building context for agent...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Step 3: Running agent with discovered tables...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `generate_comprehensive_dq_report` with `{'dataset_id': 'PROD_SALES.DATA_MART_MARKETING.CUSTOMERS', 'connector_type': 'snowflake', 'output_format': 'markdown'}`\n",
      "\n",
      "\n",
      "\u001b[0mRunning duplicates check...\n",
      "--- Loading data for: PROD_SALES.DATA_MART_MARKETING.CUSTOMERS using SNOWFLAKE connector ---\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `generate_comprehensive_dq_report` with `{'dataset_id': 'PROD_SALES.DATA_MART_MARKETING.CUSTOMERS', 'connector_type': 'snowflake', 'output_format': 'markdown'}`\n",
      "\n",
      "\n",
      "\u001b[0mRunning duplicates check...\n",
      "--- Loading data for: PROD_SALES.DATA_MART_MARKETING.CUSTOMERS using SNOWFLAKE connector ---\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "‚úì Loaded 37811 rows from Snowflake\n",
      "‚úì Loaded 37811 rows from Snowflake\n",
      "‚úì Disconnected from Snowflake\n",
      "Running null_values check...\n",
      "--- Loading data for: PROD_SALES.DATA_MART_MARKETING.CUSTOMERS using SNOWFLAKE connector ---\n",
      "‚úì Disconnected from Snowflake\n",
      "Running null_values check...\n",
      "--- Loading data for: PROD_SALES.DATA_MART_MARKETING.CUSTOMERS using SNOWFLAKE connector ---\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "‚úì Loaded 37811 rows from Snowflake\n",
      "‚úì Disconnected from Snowflake\n",
      "‚úì Loaded 37811 rows from Snowflake\n",
      "‚úì Disconnected from Snowflake\n",
      "Running descriptive_stats check...\n",
      "--- Loading data for: PROD_SALES.DATA_MART_MARKETING.CUSTOMERS using SNOWFLAKE connector ---\n",
      "Running descriptive_stats check...\n",
      "--- Loading data for: PROD_SALES.DATA_MART_MARKETING.CUSTOMERS using SNOWFLAKE connector ---\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "‚úì Loaded 37811 rows from Snowflake\n",
      "‚úì Disconnected from Snowflake\n",
      "‚úì Converted 'CUSTOMER_ID' to categorical for descriptive statistics\n",
      "‚úì Loaded 37811 rows from Snowflake\n",
      "‚úì Disconnected from Snowflake\n",
      "‚úì Converted 'CUSTOMER_ID' to categorical for descriptive statistics\n",
      "\u001b[33;1m\u001b[1;3m{'dataset_id': 'PROD_SALES.DATA_MART_MARKETING.CUSTOMERS', 'connector_type': 'snowflake', 'report_format': 'markdown', 'report_content': '# Data Quality Assessment Report\\n\\n## Dataset Information\\n- **Dataset**: `PROD_SALES.DATA_MART_MARKETING.CUSTOMERS`\\n- **Connector**: SNOWFLAKE\\n- **Assessment Date**: 2025-11-27 13:52:37\\n- **Total Checks**: 3\\n\\n## Executive Summary\\n- ‚úÖ **Passed**: 2 checks\\n- ‚ùå **Failed**: 1 checks\\n- üö´ **Errors**: 0 checks\\n\\n---\\n\\n## Detailed Check Results\\n\\n### ‚úÖ Duplicates\\n\\n- **Status**: PASS\\n- **Total Rows**: 37,811\\n- **Duplicate Records**: 0 (0.00% of data)\\n- **Quality**: Excellent - No duplicate records found\\n\\n### ‚úÖ Null Values\\n\\n- **Status**: FAIL\\n- **Dataset Size**: 37,811 rows √ó 22 columns\\n- **Columns with Missing Data**: 3 out of 22 columns\\n- **Missing Data Coverage**: 13.6% of columns affected\\n\\n**Detailed Null Analysis:**\\n- `COMPANY`: 6,927 nulls (18.3%)\\n- `PHONE`: 5,794 nulls (15.3%)\\n- `ADDRESS`: 3,130 nulls (8.3%)\\n\\n### ‚úÖ Descriptive Stats\\n\\n- **Status**: PASS (Statistics Generated)\\\\n- **Columns Analyzed**: 22 columns\\\\n\\\\n**üìä Complete Statistical Summary:**\\\\n\\\\n| Column | Count | Mean | Std | Min | 25% | 50% | 75% | Max | Unique | Top | Freq |\\\\n|--------|-------|------|-----|-----|-----|-----|-----|-----|--------|-----|------|\\\\n| `CUSTOMER_ID` | 37,811.00 | - | - | - | - | - | - | - | 36,483.00 | 718.00 | 3.00 |\\\\n| `FIRST_NAME` | 37,811 | - | - | - | - | - | - | - | 690 | Michael | 846 |\\\\n| `LAST_NAME` | 37,811 | - | - | - | - | - | - | - | 1000 | Smith | 863 |\\\\n| `EMAIL` | 37,811 | - | - | - | - | - | - | - | 34131 | pbrown@example. | 8 |\\\\n| `PHONE` | 32,017 | - | - | - | - | - | - | - | 31315 | +1-493-339-0626 | 3 |\\\\n| `ADDRESS` | 34,681 | - | - | - | - | - | - | - | 33731 | 68814 Cooper La | 3 |\\\\n| `CITY` | 37,811 | - | - | - | - | - | - | - | 20395 | West Michael | 39 |\\\\n| `STATE` | 37,811 | - | - | - | - | - | - | - | 50 | Alaska | 801 |\\\\n| `ZIP_CODE` | 37,811.00 | 50,206.64 | 28,724.82 | 504.00 | 25,341.00 | 50,261.00 | 75,131.00 | 99,945.00 | - | - | - |\\\\n| `COUNTRY` | 37,811 | - | - | - | - | - | - | - | 243 | Korea | 345 |\\\\n| `DATE_OF_BIRTH` | 37,811 | - | - | - | - | - | - | - | 19125 | 1964-12-02 | 10 |\\\\n| `AGE` | 37,811.00 | 51.45 | 19.64 | 18.00 | 34.00 | 51.00 | 68.00 | 85.00 | - | - | - |\\\\n| `GENDER` | 37,811 | - | - | - | - | - | - | - | 3 | Other | 12,639 |\\\\n| `COMPANY` | 30,884 | - | - | - | - | - | - | - | 23649 | Smith and Sons | 45 |\\\\n| `JOB_TITLE` | 37,811 | - | - | - | - | - | - | - | 639 | Commercial art  | 93 |\\\\n| `INCOME` | 37,811.00 | 114,325.32 | 45,228.85 | 4,171.00 | 80,369.00 | 114,162.00 | 146,245.00 | 255,659.00 | - | - | - |\\\\n| `ACCOUNT_BALANCE` | 37,811 | - | - | - | - | - | - | - | 36362 | 48185.59 | 3 |\\\\n| `CREDIT_SCORE` | 37,811.00 | 575.36 | 159.33 | 300.00 | 437.00 | 575.00 | 714.00 | 850.00 | - | - | - |\\\\n| `REGISTRATION_DATE` | 37,811 | - | - | - | - | - | - | - | 1827 | 2024-08-23 | 42 |\\\\n| `LAST_LOGIN` | 37,811 | - | - | - | - | - | - | - | 90 | 2025-10-09 | 470 |\\\\n| `IS_ACTIVE` | 37,811 | - | - | - | - | - | - | - | 2 | False | 18,926 |\\\\n| `CUSTOMER_SEGMENT` | 37,811 | - | - | - | - | - | - | - | 4 | Standard | 9,531 |\\\\n\\n---\\n\\n## Recommendations\\n\\n1. **Implement Null Handling Strategy**\\n   - Columns `COMPANY`, `PHONE`, `ADDRESS` have 5-20% null values. Consider implementing NOT NULL constraints, data validation rules, or imputation strategies based on business logic.\\n   - *Priority*: Medium\\n\\n2. **Enhance Data Quality Processes**\\n   - 67% pass rate indicates room for improvement. Implement automated quality gates, exception handling, and proactive monitoring for sustained quality.\\n   - *Priority*: Medium\\n\\n3. **High Cardinality in CUSTOMER_ID**\\n   - Column `CUSTOMER_ID` has very high cardinality (36,483 unique values). Consider data normalization, categorization, or indexing strategies for performance.\\n   - *Priority*: Low\\n\\n4. **High Cardinality in PHONE**\\n   - Column `PHONE` has very high cardinality (31,315 unique values). Consider data normalization, categorization, or indexing strategies for performance.\\n   - *Priority*: Low\\n\\n5. **High Cardinality in ADDRESS**\\n   - Column `ADDRESS` has very high cardinality (33,731 unique values). Consider data normalization, categorization, or indexing strategies for performance.\\n   - *Priority*: Low\\n\\n6. **High Cardinality in ACCOUNT_BALANCE**\\n   - Column `ACCOUNT_BALANCE` has very high cardinality (36,362 unique values). Consider data normalization, categorization, or indexing strategies for performance.\\n   - *Priority*: Low\\n\\n7. **Data Documentation and Profiling**\\n   - Dataset has 22 columns. Consider creating data dictionaries, establishing column-level monitoring, and implementing regular statistical profiling to track data drift over time.\\n   - *Priority*: Low\\n\\n---\\n\\n## Report Generation\\n- **Generated by**: LLM Data Quality Agent\\n- **Generation Time**: 2025-11-27 13:52:37\\n- **Report Format**: Markdown\\n\\n*This report was automatically generated. Please review recommendations and take appropriate action.*\\n', 'summary': {'total_checks': 3, 'passed_checks': 2, 'failed_checks': 1, 'error_checks': 0, 'pass_rate': '66.7%'}, 'recommendations_count': 7, 'status': 'success'}\u001b[0m\u001b[33;1m\u001b[1;3m{'dataset_id': 'PROD_SALES.DATA_MART_MARKETING.CUSTOMERS', 'connector_type': 'snowflake', 'report_format': 'markdown', 'report_content': '# Data Quality Assessment Report\\n\\n## Dataset Information\\n- **Dataset**: `PROD_SALES.DATA_MART_MARKETING.CUSTOMERS`\\n- **Connector**: SNOWFLAKE\\n- **Assessment Date**: 2025-11-27 13:52:37\\n- **Total Checks**: 3\\n\\n## Executive Summary\\n- ‚úÖ **Passed**: 2 checks\\n- ‚ùå **Failed**: 1 checks\\n- üö´ **Errors**: 0 checks\\n\\n---\\n\\n## Detailed Check Results\\n\\n### ‚úÖ Duplicates\\n\\n- **Status**: PASS\\n- **Total Rows**: 37,811\\n- **Duplicate Records**: 0 (0.00% of data)\\n- **Quality**: Excellent - No duplicate records found\\n\\n### ‚úÖ Null Values\\n\\n- **Status**: FAIL\\n- **Dataset Size**: 37,811 rows √ó 22 columns\\n- **Columns with Missing Data**: 3 out of 22 columns\\n- **Missing Data Coverage**: 13.6% of columns affected\\n\\n**Detailed Null Analysis:**\\n- `COMPANY`: 6,927 nulls (18.3%)\\n- `PHONE`: 5,794 nulls (15.3%)\\n- `ADDRESS`: 3,130 nulls (8.3%)\\n\\n### ‚úÖ Descriptive Stats\\n\\n- **Status**: PASS (Statistics Generated)\\\\n- **Columns Analyzed**: 22 columns\\\\n\\\\n**üìä Complete Statistical Summary:**\\\\n\\\\n| Column | Count | Mean | Std | Min | 25% | 50% | 75% | Max | Unique | Top | Freq |\\\\n|--------|-------|------|-----|-----|-----|-----|-----|-----|--------|-----|------|\\\\n| `CUSTOMER_ID` | 37,811.00 | - | - | - | - | - | - | - | 36,483.00 | 718.00 | 3.00 |\\\\n| `FIRST_NAME` | 37,811 | - | - | - | - | - | - | - | 690 | Michael | 846 |\\\\n| `LAST_NAME` | 37,811 | - | - | - | - | - | - | - | 1000 | Smith | 863 |\\\\n| `EMAIL` | 37,811 | - | - | - | - | - | - | - | 34131 | pbrown@example. | 8 |\\\\n| `PHONE` | 32,017 | - | - | - | - | - | - | - | 31315 | +1-493-339-0626 | 3 |\\\\n| `ADDRESS` | 34,681 | - | - | - | - | - | - | - | 33731 | 68814 Cooper La | 3 |\\\\n| `CITY` | 37,811 | - | - | - | - | - | - | - | 20395 | West Michael | 39 |\\\\n| `STATE` | 37,811 | - | - | - | - | - | - | - | 50 | Alaska | 801 |\\\\n| `ZIP_CODE` | 37,811.00 | 50,206.64 | 28,724.82 | 504.00 | 25,341.00 | 50,261.00 | 75,131.00 | 99,945.00 | - | - | - |\\\\n| `COUNTRY` | 37,811 | - | - | - | - | - | - | - | 243 | Korea | 345 |\\\\n| `DATE_OF_BIRTH` | 37,811 | - | - | - | - | - | - | - | 19125 | 1964-12-02 | 10 |\\\\n| `AGE` | 37,811.00 | 51.45 | 19.64 | 18.00 | 34.00 | 51.00 | 68.00 | 85.00 | - | - | - |\\\\n| `GENDER` | 37,811 | - | - | - | - | - | - | - | 3 | Other | 12,639 |\\\\n| `COMPANY` | 30,884 | - | - | - | - | - | - | - | 23649 | Smith and Sons | 45 |\\\\n| `JOB_TITLE` | 37,811 | - | - | - | - | - | - | - | 639 | Commercial art  | 93 |\\\\n| `INCOME` | 37,811.00 | 114,325.32 | 45,228.85 | 4,171.00 | 80,369.00 | 114,162.00 | 146,245.00 | 255,659.00 | - | - | - |\\\\n| `ACCOUNT_BALANCE` | 37,811 | - | - | - | - | - | - | - | 36362 | 48185.59 | 3 |\\\\n| `CREDIT_SCORE` | 37,811.00 | 575.36 | 159.33 | 300.00 | 437.00 | 575.00 | 714.00 | 850.00 | - | - | - |\\\\n| `REGISTRATION_DATE` | 37,811 | - | - | - | - | - | - | - | 1827 | 2024-08-23 | 42 |\\\\n| `LAST_LOGIN` | 37,811 | - | - | - | - | - | - | - | 90 | 2025-10-09 | 470 |\\\\n| `IS_ACTIVE` | 37,811 | - | - | - | - | - | - | - | 2 | False | 18,926 |\\\\n| `CUSTOMER_SEGMENT` | 37,811 | - | - | - | - | - | - | - | 4 | Standard | 9,531 |\\\\n\\n---\\n\\n## Recommendations\\n\\n1. **Implement Null Handling Strategy**\\n   - Columns `COMPANY`, `PHONE`, `ADDRESS` have 5-20% null values. Consider implementing NOT NULL constraints, data validation rules, or imputation strategies based on business logic.\\n   - *Priority*: Medium\\n\\n2. **Enhance Data Quality Processes**\\n   - 67% pass rate indicates room for improvement. Implement automated quality gates, exception handling, and proactive monitoring for sustained quality.\\n   - *Priority*: Medium\\n\\n3. **High Cardinality in CUSTOMER_ID**\\n   - Column `CUSTOMER_ID` has very high cardinality (36,483 unique values). Consider data normalization, categorization, or indexing strategies for performance.\\n   - *Priority*: Low\\n\\n4. **High Cardinality in PHONE**\\n   - Column `PHONE` has very high cardinality (31,315 unique values). Consider data normalization, categorization, or indexing strategies for performance.\\n   - *Priority*: Low\\n\\n5. **High Cardinality in ADDRESS**\\n   - Column `ADDRESS` has very high cardinality (33,731 unique values). Consider data normalization, categorization, or indexing strategies for performance.\\n   - *Priority*: Low\\n\\n6. **High Cardinality in ACCOUNT_BALANCE**\\n   - Column `ACCOUNT_BALANCE` has very high cardinality (36,362 unique values). Consider data normalization, categorization, or indexing strategies for performance.\\n   - *Priority*: Low\\n\\n7. **Data Documentation and Profiling**\\n   - Dataset has 22 columns. Consider creating data dictionaries, establishing column-level monitoring, and implementing regular statistical profiling to track data drift over time.\\n   - *Priority*: Low\\n\\n---\\n\\n## Report Generation\\n- **Generated by**: LLM Data Quality Agent\\n- **Generation Time**: 2025-11-27 13:52:37\\n- **Report Format**: Markdown\\n\\n*This report was automatically generated. Please review recommendations and take appropriate action.*\\n', 'summary': {'total_checks': 3, 'passed_checks': 2, 'failed_checks': 1, 'error_checks': 0, 'pass_rate': '66.7%'}, 'recommendations_count': 7, 'status': 'success'}\u001b[0m\u001b[32;1m\u001b[1;3m### Comprehensive Data Quality Report for `PROD_SALES.DATA_MART_MARKETING.CUSTOMERS`\n",
      "\n",
      "---\n",
      "\n",
      "#### **Dataset Information**\n",
      "- **Dataset**: `PROD_SALES.DATA_MART_MARKETING.CUSTOMERS`\n",
      "- **Connector**: SNOWFLAKE\n",
      "- **Assessment Date**: 2025-11-27\n",
      "- **Total Rows**: 37,811\n",
      "- **Total Columns**: 22\n",
      "\n",
      "---\n",
      "\n",
      "### **Executive Summary**\n",
      "- ‚úÖ **Passed Checks**: 2\n",
      "- ‚ùå **Failed Checks**: 1\n",
      "- üö´ **Errors**: 0\n",
      "- **Pass Rate**: 66.7%\n",
      "\n",
      "---\n",
      "\n",
      "### **Detailed Check Results**\n",
      "\n",
      "#### ‚úÖ **Duplicates**\n",
      "- **Status**: PASS\n",
      "- **Duplicate Records**: 0 (0.00% of data)\n",
      "- **Quality**: Excellent - No duplicate records found.\n",
      "\n",
      "---\n",
      "\n",
      "#### ‚ùå **Null Values**\n",
      "- **Status**: FAIL\n",
      "- **Columns with Missing Data**: 3 out of 22 columns\n",
      "- **Missing Data Coverage**: 13.6% of columns affected\n",
      "\n",
      "**Missing Data Details**:\n",
      "- `COMPANY`: 6,927 nulls (18.3%)\n",
      "- `PHONE`: 5,794 nulls (15.3%)\n",
      "- `ADDRESS`: 3,130 nulls (8.3%)\n",
      "\n",
      "---\n",
      "\n",
      "#### ‚úÖ **Descriptive Statistics**\n",
      "- **Status**: PASS\n",
      "- **Columns Analyzed**: 22\n",
      "\n",
      "**üìä Complete Statistical Summary**:\n",
      "\n",
      "| Column              | Count     | Mean       | Std        | Min       | 25%       | 50%       | 75%       | Max       | Unique    | Top               | Freq |\n",
      "|---------------------|-----------|------------|------------|-----------|-----------|-----------|-----------|-----------|-----------|-------------------|------|\n",
      "| `CUSTOMER_ID`       | 37,811.00 | -          | -          | -         | -         | -         | -         | -         | 36,483.00 | 718.00           | 3    |\n",
      "| `FIRST_NAME`        | 37,811    | -          | -          | -         | -         | -         | -         | -         | 690       | Michael           | 846  |\n",
      "| `LAST_NAME`         | 37,811    | -          | -          | -         | -         | -         | -         | -         | 1,000     | Smith             | 863  |\n",
      "| `EMAIL`             | 37,811    | -          | -          | -         | -         | -         | -         | -         | 34,131    | pbrown@example.   | 8    |\n",
      "| `PHONE`             | 32,017    | -          | -          | -         | -         | -         | -         | -         | 31,315    | +1-493-339-0626   | 3    |\n",
      "| `ADDRESS`           | 34,681    | -          | -          | -         | -         | -         | -         | -         | 33,731    | 68814 Cooper La   | 3    |\n",
      "| `CITY`              | 37,811    | -          | -          | -         | -         | -         | -         | -         | 20,395    | West Michael      | 39   |\n",
      "| `STATE`             | 37,811    | -          | -          | -         | -         | -         | -         | -         | 50        | Alaska            | 801  |\n",
      "| `ZIP_CODE`          | 37,811.00 | 50,206.64  | 28,724.82  | 504.00    | 25,341.00 | 50,261.00 | 75,131.00 | 99,945.00 | -         | -                 | -    |\n",
      "| `COUNTRY`           | 37,811    | -          | -          | -         | -         | -         | -         | -         | 243       | Korea             | 345  |\n",
      "| `DATE_OF_BIRTH`     | 37,811    | -          | -          | -         | -         | -         | -         | -         | 19,125    | 1964-12-02        | 10   |\n",
      "| `AGE`               | 37,811.00 | 51.45      | 19.64      | 18.00     | 34.00     | 51.00     | 68.00     | 85.00     | -         | -                 | -    |\n",
      "| `GENDER`            | 37,811    | -          | -          | -         | -         | -         | -         | -         | 3         | Other             | 12,639 |\n",
      "| `COMPANY`           | 30,884    | -          | -          | -         | -         | -         | -         | -         | 23,649    | Smith and Sons    | 45   |\n",
      "| `JOB_TITLE`         | 37,811    | -          | -          | -         | -         | -         | -         | -         | 639       | Commercial art    | 93   |\n",
      "| `INCOME`            | 37,811.00 | 114,325.32 | 45,228.85  | 4,171.00  | 80,369.00 | 114,162.00 | 146,245.00 | 255,659.00 | -         | -                 | -    |\n",
      "| `ACCOUNT_BALANCE`   | 37,811    | -          | -          | -         | -         | -         | -         | -         | 36,362    | 48,185.59         | 3    |\n",
      "| `CREDIT_SCORE`      | 37,811.00 | 575.36     | 159.33     | 300.00    | 437.00    | 575.00    | 714.00    | 850.00    | -         | -                 | -    |\n",
      "| `REGISTRATION_DATE` | 37,811    | -          | -          | -         | -         | -         | -         | -         | 1,827     | 2024-08-23        | 42   |\n",
      "| `LAST_LOGIN`        | 37,811    | -          | -          | -         | -         | -         | -         | -         | 90        | 2025-10-09        | 470  |\n",
      "| `IS_ACTIVE`         | 37,811    | -          | -          | -         | -         | -         | -         | -         | 2         | False             | 18,926 |\n",
      "| `CUSTOMER_SEGMENT`  | 37,811    | -          | -          | -         | -         | -         | -         | -         | 4         | Standard          | 9,531 |\n",
      "\n",
      "---\n",
      "\n",
      "### **Recommendations**\n",
      "1. **Implement Null Handling Strategy**\n",
      "   - Columns `COMPANY`, `PHONE`, `ADDRESS` have 5-20% null values. Consider implementing NOT NULL constraints, data validation rules, or imputation strategies based on business logic.\n",
      "   - *Priority*: Medium\n",
      "\n",
      "2. **Enhance Data Quality Processes**\n",
      "   - 67% pass rate indicates room for improvement. Implement automated quality gates, exception handling, and proactive monitoring for sustained quality.\n",
      "   - *Priority*: Medium\n",
      "\n",
      "3. **High Cardinality in CUSTOMER_ID**\n",
      "   - Column `CUSTOMER_ID` has very high cardinality (36,483 unique values). Consider data normalization, categorization, or indexing strategies for performance.\n",
      "   - *Priority*: Low\n",
      "\n",
      "4. **High Cardinality in PHONE**\n",
      "   - Column `PHONE` has very high cardinality (31,315 unique values). Consider data normalization, categorization, or indexing strategies for performance.\n",
      "   - *Priority*: Low\n",
      "\n",
      "5. **High Cardinality in ADDRESS**\n",
      "   - Column `ADDRESS` has very high cardinality (33,731 unique values). Consider data normalization, categorization, or indexing strategies for performance.\n",
      "   - *Priority*: Low\n",
      "\n",
      "6. **High Cardinality in ACCOUNT_BALANCE**\n",
      "   - Column `ACCOUNT_BALANCE` has very high cardinality (36,362 unique values). Consider data normalization, categorization, or indexing strategies for performance.\n",
      "   - *Priority*: Low\n",
      "\n",
      "7. **Data Documentation and Profiling**\n",
      "   - Dataset has 22 columns. Consider creating data dictionaries, establishing column-level monitoring, and implementing regular statistical profiling to track data drift over time.\n",
      "   - *Priority*: Low\n",
      "\n",
      "---\n",
      "\n",
      "### **Report Generation**\n",
      "- **Generated by**: LLM Data Quality Agent\n",
      "- **Generation Time**: 2025-11-27\n",
      "- **Report Format**: Markdown\n",
      "\n",
      "*This report was automatically generated. Please review recommendations and take appropriate action.*\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "======================================================================\n",
      "RESULT\n",
      "======================================================================\n",
      "\n",
      "\u001b[32;1m\u001b[1;3m### Comprehensive Data Quality Report for `PROD_SALES.DATA_MART_MARKETING.CUSTOMERS`\n",
      "\n",
      "---\n",
      "\n",
      "#### **Dataset Information**\n",
      "- **Dataset**: `PROD_SALES.DATA_MART_MARKETING.CUSTOMERS`\n",
      "- **Connector**: SNOWFLAKE\n",
      "- **Assessment Date**: 2025-11-27\n",
      "- **Total Rows**: 37,811\n",
      "- **Total Columns**: 22\n",
      "\n",
      "---\n",
      "\n",
      "### **Executive Summary**\n",
      "- ‚úÖ **Passed Checks**: 2\n",
      "- ‚ùå **Failed Checks**: 1\n",
      "- üö´ **Errors**: 0\n",
      "- **Pass Rate**: 66.7%\n",
      "\n",
      "---\n",
      "\n",
      "### **Detailed Check Results**\n",
      "\n",
      "#### ‚úÖ **Duplicates**\n",
      "- **Status**: PASS\n",
      "- **Duplicate Records**: 0 (0.00% of data)\n",
      "- **Quality**: Excellent - No duplicate records found.\n",
      "\n",
      "---\n",
      "\n",
      "#### ‚ùå **Null Values**\n",
      "- **Status**: FAIL\n",
      "- **Columns with Missing Data**: 3 out of 22 columns\n",
      "- **Missing Data Coverage**: 13.6% of columns affected\n",
      "\n",
      "**Missing Data Details**:\n",
      "- `COMPANY`: 6,927 nulls (18.3%)\n",
      "- `PHONE`: 5,794 nulls (15.3%)\n",
      "- `ADDRESS`: 3,130 nulls (8.3%)\n",
      "\n",
      "---\n",
      "\n",
      "#### ‚úÖ **Descriptive Statistics**\n",
      "- **Status**: PASS\n",
      "- **Columns Analyzed**: 22\n",
      "\n",
      "**üìä Complete Statistical Summary**:\n",
      "\n",
      "| Column              | Count     | Mean       | Std        | Min       | 25%       | 50%       | 75%       | Max       | Unique    | Top               | Freq |\n",
      "|---------------------|-----------|------------|------------|-----------|-----------|-----------|-----------|-----------|-----------|-------------------|------|\n",
      "| `CUSTOMER_ID`       | 37,811.00 | -          | -          | -         | -         | -         | -         | -         | 36,483.00 | 718.00           | 3    |\n",
      "| `FIRST_NAME`        | 37,811    | -          | -          | -         | -         | -         | -         | -         | 690       | Michael           | 846  |\n",
      "| `LAST_NAME`         | 37,811    | -          | -          | -         | -         | -         | -         | -         | 1,000     | Smith             | 863  |\n",
      "| `EMAIL`             | 37,811    | -          | -          | -         | -         | -         | -         | -         | 34,131    | pbrown@example.   | 8    |\n",
      "| `PHONE`             | 32,017    | -          | -          | -         | -         | -         | -         | -         | 31,315    | +1-493-339-0626   | 3    |\n",
      "| `ADDRESS`           | 34,681    | -          | -          | -         | -         | -         | -         | -         | 33,731    | 68814 Cooper La   | 3    |\n",
      "| `CITY`              | 37,811    | -          | -          | -         | -         | -         | -         | -         | 20,395    | West Michael      | 39   |\n",
      "| `STATE`             | 37,811    | -          | -          | -         | -         | -         | -         | -         | 50        | Alaska            | 801  |\n",
      "| `ZIP_CODE`          | 37,811.00 | 50,206.64  | 28,724.82  | 504.00    | 25,341.00 | 50,261.00 | 75,131.00 | 99,945.00 | -         | -                 | -    |\n",
      "| `COUNTRY`           | 37,811    | -          | -          | -         | -         | -         | -         | -         | 243       | Korea             | 345  |\n",
      "| `DATE_OF_BIRTH`     | 37,811    | -          | -          | -         | -         | -         | -         | -         | 19,125    | 1964-12-02        | 10   |\n",
      "| `AGE`               | 37,811.00 | 51.45      | 19.64      | 18.00     | 34.00     | 51.00     | 68.00     | 85.00     | -         | -                 | -    |\n",
      "| `GENDER`            | 37,811    | -          | -          | -         | -         | -         | -         | -         | 3         | Other             | 12,639 |\n",
      "| `COMPANY`           | 30,884    | -          | -          | -         | -         | -         | -         | -         | 23,649    | Smith and Sons    | 45   |\n",
      "| `JOB_TITLE`         | 37,811    | -          | -          | -         | -         | -         | -         | -         | 639       | Commercial art    | 93   |\n",
      "| `INCOME`            | 37,811.00 | 114,325.32 | 45,228.85  | 4,171.00  | 80,369.00 | 114,162.00 | 146,245.00 | 255,659.00 | -         | -                 | -    |\n",
      "| `ACCOUNT_BALANCE`   | 37,811    | -          | -          | -         | -         | -         | -         | -         | 36,362    | 48,185.59         | 3    |\n",
      "| `CREDIT_SCORE`      | 37,811.00 | 575.36     | 159.33     | 300.00    | 437.00    | 575.00    | 714.00    | 850.00    | -         | -                 | -    |\n",
      "| `REGISTRATION_DATE` | 37,811    | -          | -          | -         | -         | -         | -         | -         | 1,827     | 2024-08-23        | 42   |\n",
      "| `LAST_LOGIN`        | 37,811    | -          | -          | -         | -         | -         | -         | -         | 90        | 2025-10-09        | 470  |\n",
      "| `IS_ACTIVE`         | 37,811    | -          | -          | -         | -         | -         | -         | -         | 2         | False             | 18,926 |\n",
      "| `CUSTOMER_SEGMENT`  | 37,811    | -          | -          | -         | -         | -         | -         | -         | 4         | Standard          | 9,531 |\n",
      "\n",
      "---\n",
      "\n",
      "### **Recommendations**\n",
      "1. **Implement Null Handling Strategy**\n",
      "   - Columns `COMPANY`, `PHONE`, `ADDRESS` have 5-20% null values. Consider implementing NOT NULL constraints, data validation rules, or imputation strategies based on business logic.\n",
      "   - *Priority*: Medium\n",
      "\n",
      "2. **Enhance Data Quality Processes**\n",
      "   - 67% pass rate indicates room for improvement. Implement automated quality gates, exception handling, and proactive monitoring for sustained quality.\n",
      "   - *Priority*: Medium\n",
      "\n",
      "3. **High Cardinality in CUSTOMER_ID**\n",
      "   - Column `CUSTOMER_ID` has very high cardinality (36,483 unique values). Consider data normalization, categorization, or indexing strategies for performance.\n",
      "   - *Priority*: Low\n",
      "\n",
      "4. **High Cardinality in PHONE**\n",
      "   - Column `PHONE` has very high cardinality (31,315 unique values). Consider data normalization, categorization, or indexing strategies for performance.\n",
      "   - *Priority*: Low\n",
      "\n",
      "5. **High Cardinality in ADDRESS**\n",
      "   - Column `ADDRESS` has very high cardinality (33,731 unique values). Consider data normalization, categorization, or indexing strategies for performance.\n",
      "   - *Priority*: Low\n",
      "\n",
      "6. **High Cardinality in ACCOUNT_BALANCE**\n",
      "   - Column `ACCOUNT_BALANCE` has very high cardinality (36,362 unique values). Consider data normalization, categorization, or indexing strategies for performance.\n",
      "   - *Priority*: Low\n",
      "\n",
      "7. **Data Documentation and Profiling**\n",
      "   - Dataset has 22 columns. Consider creating data dictionaries, establishing column-level monitoring, and implementing regular statistical profiling to track data drift over time.\n",
      "   - *Priority*: Low\n",
      "\n",
      "---\n",
      "\n",
      "### **Report Generation**\n",
      "- **Generated by**: LLM Data Quality Agent\n",
      "- **Generation Time**: 2025-11-27\n",
      "- **Report Format**: Markdown\n",
      "\n",
      "*This report was automatically generated. Please review recommendations and take appropriate action.*\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "======================================================================\n",
      "RESULT\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get user input for the query with a default option\n",
    "default_query = \"Generate comprehensive DQ report for prod customers table\"\n",
    "user_query = input(\"Enter your DQ check query (or press Enter to use default): \").strip() or default_query\n",
    "print(f\"Using query: {user_query}\")\n",
    "\n",
    "comprehensive_report = run_smart_dq_check(user_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4417ae09",
   "metadata": {},
   "source": [
    "Comprehensive report saving function run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f053675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smart DQ check successful - proceeding with report generation...\n",
      "Extracted info:\n",
      "   Dataset: PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "   Connector: snowflake\n",
      "\n",
      "Running comprehensive DQ assessment with reliable data sources...\n",
      "   Executing duplicates check...\n",
      "--- Loading data for: PROD_SALES.DATA_MART_MARKETING.CUSTOMERS using SNOWFLAKE connector ---\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "‚úì Loaded 37811 rows from Snowflake\n",
      "‚úì Disconnected from Snowflake\n",
      "‚úì Loaded 37811 rows from Snowflake\n",
      "‚úì Disconnected from Snowflake\n",
      "   Executing null_values check...\n",
      "--- Loading data for: PROD_SALES.DATA_MART_MARKETING.CUSTOMERS using SNOWFLAKE connector ---\n",
      "   Executing null_values check...\n",
      "--- Loading data for: PROD_SALES.DATA_MART_MARKETING.CUSTOMERS using SNOWFLAKE connector ---\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "‚úì Loaded 37811 rows from Snowflake\n",
      "‚úì Disconnected from Snowflake\n",
      "‚úì Loaded 37811 rows from Snowflake\n",
      "‚úì Disconnected from Snowflake\n",
      "   Executing descriptive_stats check...\n",
      "--- Loading data for: PROD_SALES.DATA_MART_MARKETING.CUSTOMERS using SNOWFLAKE connector ---\n",
      "   Executing descriptive_stats check...\n",
      "--- Loading data for: PROD_SALES.DATA_MART_MARKETING.CUSTOMERS using SNOWFLAKE connector ---\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "‚úì Loaded 37811 rows from Snowflake\n",
      "‚úì Disconnected from Snowflake\n",
      "‚úì Converted 'CUSTOMER_ID' to categorical for descriptive statistics\n",
      "‚úì Loaded 37811 rows from Snowflake\n",
      "‚úì Disconnected from Snowflake\n",
      "‚úì Converted 'CUSTOMER_ID' to categorical for descriptive statistics\n",
      "    Assessment completed using direct DQ check execution!\n",
      "    Data consistency guaranteed - no parsing errors!\n",
      "\n",
      "Generating reports using standardized templates...\n",
      "   MARKDOWN: ../reports/comprehensive_dq_report_prod_sales_customers_20251127_135251.md\n",
      "   HTML: ../reports/comprehensive_dq_report_prod_sales_customers_20251127_135251.html\n",
      "   JSON: ../reports/comprehensive_dq_report_prod_sales_customers_20251127_135251.json\n",
      "    Assessment completed using direct DQ check execution!\n",
      "    Data consistency guaranteed - no parsing errors!\n",
      "\n",
      "Generating reports using standardized templates...\n",
      "   MARKDOWN: ../reports/comprehensive_dq_report_prod_sales_customers_20251127_135251.md\n",
      "   HTML: ../reports/comprehensive_dq_report_prod_sales_customers_20251127_135251.html\n",
      "   JSON: ../reports/comprehensive_dq_report_prod_sales_customers_20251127_135251.json\n"
     ]
    }
   ],
   "source": [
    "# Initialize the report processor\n",
    "processor = SmartDQReportProcessor(reports_dir=\"../reports\")\n",
    "\n",
    "# Process the comprehensive report (handles validation, extraction, checks, and file generation)\n",
    "result = processor.process_comprehensive_report(comprehensive_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4adb598",
   "metadata": {},
   "source": [
    "## Single-Quality Check Report Creation\n",
    "\n",
    "Run only single detection and save results to a focused report file. In case single quality checks needed and saved seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10d1403e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running duplicate-only analysis: Check for duplicates in prod customers table\n",
      "\n",
      "======================================================================\n",
      "SMART DATA QUALITY CHECK\n",
      "======================================================================\n",
      "User Query: Check for duplicates in prod customers table\n",
      "\n",
      "Step 1: Discovering relevant tables...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Number of requested results 20 is greater than number of elements in index 9, updating n_results = 9\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Number of requested results 20 is greater than number of elements in index 9, updating n_results = 9\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 2 relevant table(s) (‚â•5% relevance):\n",
      "\n",
      "  1. [SNOWFLAKE] PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "     Relevance: 34.89% ‚úì\n",
      "\n",
      "  2. [SNOWFLAKE] PROD_SALES.DATA_MART_MANUFACTURING.PRODUCTS\n",
      "     Relevance: 6.91% ‚úì\n",
      "\n",
      "Step 2: Building context for agent...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Step 3: Running agent with discovered tables...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `check_dataset_duplicates` with `{'dataset_id': 'PROD_SALES.DATA_MART_MARKETING.CUSTOMERS', 'connector_type': 'snowflake'}`\n",
      "\n",
      "\n",
      "\u001b[0m--- Loading data for: PROD_SALES.DATA_MART_MARKETING.CUSTOMERS using SNOWFLAKE connector ---\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `check_dataset_duplicates` with `{'dataset_id': 'PROD_SALES.DATA_MART_MARKETING.CUSTOMERS', 'connector_type': 'snowflake'}`\n",
      "\n",
      "\n",
      "\u001b[0m--- Loading data for: PROD_SALES.DATA_MART_MARKETING.CUSTOMERS using SNOWFLAKE connector ---\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "‚úì Loaded 37811 rows from Snowflake\n",
      "‚úì Disconnected from Snowflake\n",
      "‚úì Loaded 37811 rows from Snowflake\n",
      "‚úì Disconnected from Snowflake\n",
      "\u001b[36;1m\u001b[1;3m{'dataset_id': 'PROD_SALES.DATA_MART_MARKETING.CUSTOMERS', 'total_rows': 37811, 'duplicate_qty': 0, 'status': 'success'}\u001b[0m\u001b[36;1m\u001b[1;3m{'dataset_id': 'PROD_SALES.DATA_MART_MARKETING.CUSTOMERS', 'total_rows': 37811, 'duplicate_qty': 0, 'status': 'success'}\u001b[0m\u001b[32;1m\u001b[1;3mThe duplicate check for the table `PROD_SALES.DATA_MART_MARKETING.CUSTOMERS` in Snowflake has been completed successfully. Here are the results:\n",
      "\n",
      "- **Total Rows**: 37,811\n",
      "- **Duplicate Rows**: 0\n",
      "\n",
      "This indicates that there are no duplicate records in the dataset. The data appears to be clean in terms of duplicate entries.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "======================================================================\n",
      "RESULT\n",
      "======================================================================\n",
      "\n",
      "\u001b[32;1m\u001b[1;3mThe duplicate check for the table `PROD_SALES.DATA_MART_MARKETING.CUSTOMERS` in Snowflake has been completed successfully. Here are the results:\n",
      "\n",
      "- **Total Rows**: 37,811\n",
      "- **Duplicate Rows**: 0\n",
      "\n",
      "This indicates that there are no duplicate records in the dataset. The data appears to be clean in terms of duplicate entries.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "======================================================================\n",
      "RESULT\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For DUPLICATE-ONLY analysis - use agent with specific query\n",
    "duplicate_query = \"Check for duplicates in prod customers table\"\n",
    "print(f\"Running duplicate-only analysis: {duplicate_query}\")\n",
    "\n",
    "duplicate_result = run_smart_dq_check(duplicate_query)\n",
    "\n",
    "# Save to a simple duplicate-focused file\n",
    "duplicate_report_content = f\"\"\"# Duplicate Analysis Report\n",
    "Generated: {datetime.now()}\n",
    "Query: {duplicate_query}\n",
    "\n",
    "## Results:\n",
    "{duplicate_result['output']}\n",
    "\"\"\"\n",
    "\n",
    "# Save to reports folder\n",
    "duplicate_file_path = \"../reports/duplicate_only_analysis.md\"\n",
    "with open(duplicate_file_path, \"w\") as f:\n",
    "    f.write(duplicate_report_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "626f034d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running null-only analysis: Check for null values in prod customers table\n",
      "\n",
      "======================================================================\n",
      "SMART DATA QUALITY CHECK\n",
      "======================================================================\n",
      "User Query: Check for null values in prod customers table\n",
      "\n",
      "Step 1: Discovering relevant tables...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Number of requested results 20 is greater than number of elements in index 9, updating n_results = 9\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Number of requested results 20 is greater than number of elements in index 9, updating n_results = 9\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 1 relevant table(s) (‚â•5% relevance):\n",
      "\n",
      "  1. [SNOWFLAKE] PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "     Relevance: 28.18% ‚úì\n",
      "\n",
      "Step 2: Building context for agent...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Step 3: Running agent with discovered tables...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `check_dataset_null_values` with `{'dataset_id': 'PROD_SALES.DATA_MART_MARKETING.CUSTOMERS', 'connector_type': 'snowflake'}`\n",
      "\n",
      "\n",
      "\u001b[0m--- Loading data for: PROD_SALES.DATA_MART_MARKETING.CUSTOMERS using SNOWFLAKE connector ---\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `check_dataset_null_values` with `{'dataset_id': 'PROD_SALES.DATA_MART_MARKETING.CUSTOMERS', 'connector_type': 'snowflake'}`\n",
      "\n",
      "\n",
      "\u001b[0m--- Loading data for: PROD_SALES.DATA_MART_MARKETING.CUSTOMERS using SNOWFLAKE connector ---\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "‚úì Loaded 37811 rows from Snowflake\n",
      "‚úì Loaded 37811 rows from Snowflake\n",
      "‚úì Disconnected from Snowflake\n",
      "‚úì Disconnected from Snowflake\n",
      "\u001b[33;1m\u001b[1;3m{'dataset_id': 'PROD_SALES.DATA_MART_MARKETING.CUSTOMERS', 'total_rows': 37811, 'total_columns': 22, 'columns_with_nulls': 3, 'null_analysis': [{'column_name': 'COMPANY', 'null_count': 6927, 'null_percentage': 18.32}, {'column_name': 'PHONE', 'null_count': 5794, 'null_percentage': 15.32}, {'column_name': 'ADDRESS', 'null_count': 3130, 'null_percentage': 8.28}], 'status': 'success'}\u001b[0m\u001b[33;1m\u001b[1;3m{'dataset_id': 'PROD_SALES.DATA_MART_MARKETING.CUSTOMERS', 'total_rows': 37811, 'total_columns': 22, 'columns_with_nulls': 3, 'null_analysis': [{'column_name': 'COMPANY', 'null_count': 6927, 'null_percentage': 18.32}, {'column_name': 'PHONE', 'null_count': 5794, 'null_percentage': 15.32}, {'column_name': 'ADDRESS', 'null_count': 3130, 'null_percentage': 8.28}], 'status': 'success'}\u001b[0m\u001b[32;1m\u001b[1;3m### Null Values Analysis for Table: `PROD_SALES.DATA_MART_MARKETING.CUSTOMERS`\n",
      "\n",
      "**Total Rows:** 37,811  \n",
      "**Total Columns:** 22  \n",
      "\n",
      "**Columns with Missing Data:** 3 out of 22 columns  \n",
      "\n",
      "**Missing Data Details**:\n",
      "- `COMPANY`: 6,927 nulls (18.32%)\n",
      "- `PHONE`: 5,794 nulls (15.32%)\n",
      "- `ADDRESS`: 3,130 nulls (8.28%)\n",
      "\n",
      "This detailed breakdown highlights the columns with missing data and their respective percentages. Let me know if you need further analysis or a comprehensive report!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "======================================================================\n",
      "RESULT\n",
      "======================================================================\n",
      "\n",
      "\u001b[32;1m\u001b[1;3m### Null Values Analysis for Table: `PROD_SALES.DATA_MART_MARKETING.CUSTOMERS`\n",
      "\n",
      "**Total Rows:** 37,811  \n",
      "**Total Columns:** 22  \n",
      "\n",
      "**Columns with Missing Data:** 3 out of 22 columns  \n",
      "\n",
      "**Missing Data Details**:\n",
      "- `COMPANY`: 6,927 nulls (18.32%)\n",
      "- `PHONE`: 5,794 nulls (15.32%)\n",
      "- `ADDRESS`: 3,130 nulls (8.28%)\n",
      "\n",
      "This detailed breakdown highlights the columns with missing data and their respective percentages. Let me know if you need further analysis or a comprehensive report!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "======================================================================\n",
      "RESULT\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For NULL-ONLY analysis - use agent with specific query\n",
    "null_query = \"Check for null values in prod customers table\"\n",
    "print(f\"Running null-only analysis: {null_query}\")\n",
    "\n",
    "null_result = run_smart_dq_check(null_query)\n",
    "\n",
    "# Save to a simple null-focused file\n",
    "null_report_content = f\"\"\"# Null Analysis Report\n",
    "Generated: {datetime.now()}\n",
    "Query: {null_query}\n",
    "\n",
    "## Results:\n",
    "{null_result['output']}\n",
    "\"\"\"\n",
    "\n",
    "# Save to reports folder\n",
    "null_file_path = \"../reports/null_only_analysis.md\"\n",
    "with open(null_file_path, \"w\") as f:\n",
    "    f.write(null_report_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8798ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running statistics-only analysis: Check descriptive statistics for prod customers table\n",
      "\n",
      "======================================================================\n",
      "SMART DATA QUALITY CHECK\n",
      "======================================================================\n",
      "User Query: Check descriptive statistics for prod customers table\n",
      "\n",
      "Step 1: Discovering relevant tables...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Number of requested results 20 is greater than number of elements in index 9, updating n_results = 9\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 3 relevant table(s) (‚â•5% relevance):\n",
      "\n",
      "  1. [SNOWFLAKE] PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "     Relevance: 40.41% ‚úì\n",
      "\n",
      "  2. [SNOWFLAKE] PROD_SALES.DATA_MART_MANUFACTURING.PRODUCTS\n",
      "     Relevance: 31.84% ‚úì\n",
      "\n",
      "  3. [SNOWFLAKE] PROD_SALES.DATA_MART_MARKETING.CALL_CENTER\n",
      "     Relevance: 22.27% ‚úì\n",
      "\n",
      "Step 2: Building context for agent...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Step 3: Running agent with discovered tables...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `check_dataset_descriptive_stats` with `{'dataset_id': 'PROD_SALES.DATA_MART_MARKETING.CUSTOMERS', 'connector_type': 'snowflake'}`\n",
      "\n",
      "\n",
      "\u001b[0m--- Loading data for: PROD_SALES.DATA_MART_MARKETING.CUSTOMERS using SNOWFLAKE connector ---\n",
      "‚úì Connected to Snowflake: PROD_SALES.PUBLIC\n",
      "Executing query: SELECT * FROM PROD_SALES.DATA_MART_MARKETING.CUSTOMERS\n",
      "‚úì Loaded 37811 rows from Snowflake\n",
      "‚úì Disconnected from Snowflake\n",
      "‚úì Converted 'CUSTOMER_ID' to categorical for descriptive statistics\n",
      "\u001b[38;5;200m\u001b[1;3m{'dataset_id': 'PROD_SALES.DATA_MART_MARKETING.CUSTOMERS', 'descriptive_stats': {'CUSTOMER_ID': {'count': 37811.0, 'unique': 36483.0, 'top': 718.0, 'freq': 3.0, 'mean': None, 'std': None, 'min': None, '25%': None, '50%': None, '75%': None, 'max': None}, 'FIRST_NAME': {'count': 37811, 'unique': '690', 'top': 'Michael', 'freq': 846, 'mean': None, 'std': None, 'min': None, '25%': None, '50%': None, '75%': None, 'max': None}, 'LAST_NAME': {'count': 37811, 'unique': '1000', 'top': 'Smith', 'freq': 863, 'mean': None, 'std': None, 'min': None, '25%': None, '50%': None, '75%': None, 'max': None}, 'EMAIL': {'count': 37811, 'unique': '34131', 'top': 'pbrown@example.com', 'freq': 8, 'mean': None, 'std': None, 'min': None, '25%': None, '50%': None, '75%': None, 'max': None}, 'PHONE': {'count': 32017, 'unique': '31315', 'top': '+1-493-339-0626x16177', 'freq': 3, 'mean': None, 'std': None, 'min': None, '25%': None, '50%': None, '75%': None, 'max': None}, 'ADDRESS': {'count': 34681, 'unique': '33731', 'top': '68814 Cooper Lane, Raymondside, SD 84458', 'freq': 3, 'mean': None, 'std': None, 'min': None, '25%': None, '50%': None, '75%': None, 'max': None}, 'CITY': {'count': 37811, 'unique': '20395', 'top': 'West Michael', 'freq': 39, 'mean': None, 'std': None, 'min': None, '25%': None, '50%': None, '75%': None, 'max': None}, 'STATE': {'count': 37811, 'unique': '50', 'top': 'Alaska', 'freq': 801, 'mean': None, 'std': None, 'min': None, '25%': None, '50%': None, '75%': None, 'max': None}, 'ZIP_CODE': {'count': 37811.0, 'unique': None, 'top': None, 'freq': None, 'mean': 50206.63812118167, 'std': 28724.821482828218, 'min': 504.0, '25%': 25341.0, '50%': 50261.0, '75%': 75131.0, 'max': 99945.0}, 'COUNTRY': {'count': 37811, 'unique': '243', 'top': 'Korea', 'freq': 345, 'mean': None, 'std': None, 'min': None, '25%': None, '50%': None, '75%': None, 'max': None}, 'DATE_OF_BIRTH': {'count': 37811, 'unique': '19125', 'top': '1964-12-02', 'freq': 10, 'mean': None, 'std': None, 'min': None, '25%': None, '50%': None, '75%': None, 'max': None}, 'AGE': {'count': 37811.0, 'unique': None, 'top': None, 'freq': None, 'mean': 51.45161460950517, 'std': 19.64358581332872, 'min': 18.0, '25%': 34.0, '50%': 51.0, '75%': 68.0, 'max': 85.0}, 'GENDER': {'count': 37811, 'unique': '3', 'top': 'Other', 'freq': 12639, 'mean': None, 'std': None, 'min': None, '25%': None, '50%': None, '75%': None, 'max': None}, 'COMPANY': {'count': 30884, 'unique': '23649', 'top': 'Smith and Sons', 'freq': 45, 'mean': None, 'std': None, 'min': None, '25%': None, '50%': None, '75%': None, 'max': None}, 'JOB_TITLE': {'count': 37811, 'unique': '639', 'top': 'Commercial art gallery manager', 'freq': 93, 'mean': None, 'std': None, 'min': None, '25%': None, '50%': None, '75%': None, 'max': None}, 'INCOME': {'count': 37811.0, 'unique': None, 'top': None, 'freq': None, 'mean': 114325.32321282166, 'std': 45228.84608990783, 'min': 4171.0, '25%': 80369.0, '50%': 114162.0, '75%': 146245.0, 'max': 255659.0}, 'ACCOUNT_BALANCE': {'count': 37811, 'unique': '36362', 'top': '48185.59', 'freq': 3, 'mean': None, 'std': None, 'min': None, '25%': None, '50%': None, '75%': None, 'max': None}, 'CREDIT_SCORE': {'count': 37811.0, 'unique': None, 'top': None, 'freq': None, 'mean': 575.3647086826585, 'std': 159.33065549399012, 'min': 300.0, '25%': 437.0, '50%': 575.0, '75%': 714.0, 'max': 850.0}, 'REGISTRATION_DATE': {'count': 37811, 'unique': '1827', 'top': '2024-08-23', 'freq': 42, 'mean': None, 'std': None, 'min': None, '25%': None, '50%': None, '75%': None, 'max': None}, 'LAST_LOGIN': {'count': 37811, 'unique': '90', 'top': '2025-10-09', 'freq': 470, 'mean': None, 'std': None, 'min': None, '25%': None, '50%': None, '75%': None, 'max': None}, 'IS_ACTIVE': {'count': 37811, 'unique': '2', 'top': 'False', 'freq': 18926, 'mean': None, 'std': None, 'min': None, '25%': None, '50%': None, '75%': None, 'max': None}, 'CUSTOMER_SEGMENT': {'count': 37811, 'unique': '4', 'top': 'Standard', 'freq': 9531, 'mean': None, 'std': None, 'min': None, '25%': None, '50%': None, '75%': None, 'max': None}}, 'status': 'success'}\u001b[0m\u001b[32;1m\u001b[1;3m### Descriptive Statistics for Table: `PROD_SALES.DATA_MART_MARKETING.CUSTOMERS`\n",
      "\n",
      "Below is the detailed statistical breakdown for the `CUSTOMERS` table:\n",
      "\n",
      "#### Numerical Columns:\n",
      "| Column Name       | Count   | Mean       | Std Dev    | Min   | 25%   | 50%   | 75%   | Max   |\n",
      "|-------------------|---------|------------|------------|-------|-------|-------|-------|-------|\n",
      "| ZIP_CODE          | 37,811  | 50,206.64  | 28,724.82  | 504   | 25,341| 50,261| 75,131| 99,945|\n",
      "| AGE               | 37,811  | 51.45      | 19.64      | 18    | 34    | 51    | 68    | 85    |\n",
      "| INCOME            | 37,811  | 114,325.32 | 45,228.85  | 4,171 | 80,369| 114,162|146,245|255,659|\n",
      "| CREDIT_SCORE      | 37,811  | 575.36     | 159.33     | 300   | 437   | 575   | 714   | 850   |\n",
      "\n",
      "#### Categorical Columns:\n",
      "| Column Name       | Count   | Unique | Top Value                  | Frequency |\n",
      "|-------------------|---------|--------|----------------------------|-----------|\n",
      "| CUSTOMER_ID       | 37,811  | 36,483 | 718                        | 3         |\n",
      "| FIRST_NAME        | 37,811  | 690    | Michael                    | 846       |\n",
      "| LAST_NAME         | 37,811  | 1,000  | Smith                      | 863       |\n",
      "| EMAIL             | 37,811  | 34,131 | pbrown@example.com         | 8         |\n",
      "| PHONE             | 32,017  | 31,315 | +1-493-339-0626x16177      | 3         |\n",
      "| ADDRESS           | 34,681  | 33,731 | 68814 Cooper Lane, Raymondside, SD 84458 | 3         |\n",
      "| CITY              | 37,811  | 20,395 | West Michael               | 39        |\n",
      "| STATE             | 37,811  | 50     | Alaska                     | 801       |\n",
      "| COUNTRY           | 37,811  | 243    | Korea                      | 345       |\n",
      "| DATE_OF_BIRTH     | 37,811  | 19,125 | 1964-12-02                 | 10        |\n",
      "| GENDER            | 37,811  | 3      | Other                      | 12,639    |\n",
      "| COMPANY           | 30,884  | 23,649 | Smith and Sons             | 45        |\n",
      "| JOB_TITLE         | 37,811  | 639    | Commercial art gallery manager | 93        |\n",
      "| ACCOUNT_BALANCE   | 37,811  | 36,362 | 48185.59                   | 3         |\n",
      "| REGISTRATION_DATE | 37,811  | 1,827  | 2024-08-23                 | 42        |\n",
      "| LAST_LOGIN        | 37,811  | 90     | 2025-10-09                 | 470       |\n",
      "| IS_ACTIVE         | 37,811  | 2      | False                      | 18,926    |\n",
      "| CUSTOMER_SEGMENT  | 37,811  | 4      | Standard                   | 9,531     |\n",
      "\n",
      "#### Observations:\n",
      "- **Numerical Data**: Columns like `AGE`, `INCOME`, and `CREDIT_SCORE` show a wide range of values, with `INCOME` having the highest variability.\n",
      "- **Categorical Data**: The most frequent values for columns like `FIRST_NAME`, `LAST_NAME`, and `CUSTOMER_SEGMENT` indicate common patterns in customer demographics.\n",
      "- **Missing Data**: Some columns like `PHONE` and `COMPANY` have fewer counts compared to the total rows, indicating missing values.\n",
      "\n",
      "Let me know if you need further analysis or additional checks!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "======================================================================\n",
      "RESULT\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For DESCRIPTIVE STATISTICS-ONLY analysis - use agent with specific query\n",
    "stats_query = \"Check descriptive statistics for prod customers table\"\n",
    "print(f\"Running statistics-only analysis: {stats_query}\")\n",
    "\n",
    "stats_result = run_smart_dq_check(stats_query)\n",
    "\n",
    "# Save to a simple statistics-focused file\n",
    "stats_report_content = f\"\"\"# Descriptive Statistics Analysis Report\n",
    "Generated: {datetime.now()}\n",
    "Query: {stats_query}\n",
    "\n",
    "## Results:\n",
    "{stats_result['output']}\n",
    "\"\"\"\n",
    "\n",
    "# Save to reports folder\n",
    "stats_file_path = \"../reports/stats_only_analysis.md\"\n",
    "with open(stats_file_path, \"w\") as f:\n",
    "    f.write(stats_report_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-dq-agent-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
